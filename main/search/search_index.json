{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"api/","title":"API of Open-ST tools","text":"<p>Here we show the description of all commands available in the <code>openst</code> tools, which can be run as:</p> <pre><code>openst &lt;subcommand&gt;\n</code></pre>"},{"location":"api/#barcode_preprocessing","title":"<code>barcode_preprocessing</code>","text":"<p>Convert spatial barcode raw data into tabular files with barcodes and spatial coordinates.</p> <p>Usage: <pre><code>openst barcode_preprocessing [-h] --fastq-in FASTQ_IN --tilecoords-out TILECOORDS_OUT --out-suffix OUT_SUFFIX [--out-prefix OUT_PREFIX] [--crop-seq CROP_SEQ] [--rev-comp] [--single-tile] [--unsorted]\n\noptions:\n  -h, --help            show this help message and exit\n  --fastq-in FASTQ_IN   Path to the fastq file\n  --tilecoords-out TILECOORDS_OUT\n                        Directory where output files will be written to\n  --out-suffix OUT_SUFFIX\n                        Suffix added to the name of the output files (i.e., extension)\n  --out-prefix OUT_PREFIX\n                        (Optional) Prefix added to the name of the output files. Default: \"\"\n  --crop-seq CROP_SEQ   (Optional) A 'python-style' slice, used to crop input sequences. Default: \":\"\n  --rev-comp            (Optional) Apply reverse complementary after sequence cropping\n  --single-tile         (Optional) set if it is guarranteed that the input .fastq(.gz) file contains only a tile\n  --unsorted            (Optional) set when file is unsorted respect to tiles; might be slower\n</code></pre></p>"},{"location":"api/#flowcell_map","title":"<code>flowcell_map</code>","text":"<p>Convert basecalls from a whole flow cell into barcodes-to-spatial coordinates maps (tabular format) that can be used with spacemake for spatial mapping of transcriptomic libraries.</p> <p>Usage: <pre><code>openst flowcell_map [-h] --bcl-in BCL_IN --tiles-out TILES_OUT [--out-suffix OUT_SUFFIX] [--out-prefix OUT_PREFIX]\n                           [--crop-seq CROP_SEQ] [--rev-comp] [--parallel-processes PARALLEL_PROCESSES]\n\noptions:\n  -h, --help            show this help message and exit\n  --bcl-in BCL_IN       Input directory containing BCL files\n  --tiles-out TILES_OUT\n                        Output directory for tile coordinate files\n  --out-suffix OUT_SUFFIX\n                        (Optional) Suffix for output files\n  --out-prefix OUT_PREFIX\n                        (Optional) Prefix for output files\n  --crop-seq CROP_SEQ   (Optional) Python slice format for cropping sequences\n  --rev-comp            (Optional) Reverse complement the sequences\n  --parallel-processes PARALLEL_PROCESSES\n                        (Optional) Number of parallel processes to use\n</code></pre></p>"},{"location":"api/#image_stitch","title":"<code>image_stitch</code>","text":"<p>Stitch image fields of view into a single image. Currently, it only supports <code>--microscope keyence</code>, for the default microscopy setup used in our paper.</p> <p>Usage: <pre><code>openst image_stitch [-h] --image-indir IMAGE_INDIR --image-out IMAGE_OUT --imagej-bin IMAGEJ_BIN --microscope {keyence} [--no-run] [--rerun] [--metadata METADATA] [--join-zstack-regex JOIN_ZSTACK_REGEX]\n\noptions:\n  -h, --help            show this help message and exit\n  --image-indir IMAGE_INDIR\n                        path to collection of images\n  --image-out IMAGE_OUT\n                        path where to save the image (must be a filename)\n  --imagej-bin IMAGEJ_BIN\n                        path to the ImageJ/Fiji executable. Must have the Grid Collection plugin available!\n  --microscope {keyence}\n                        microscope model or imaging strategy that was used for imaging\n  --no-run              If set, do not run ImageJ, but return the command line\n  --rerun               If set, runs stitching even when the output file exists\n  --metadata METADATA   Path where the metadata will be stored. If not specified, metadata is not saved. Default: \"\"\n  --join-zstack-regex JOIN_ZSTACK_REGEX\n                        When non empty, this specifies how to find the Z location from the individual filename and will create a z-stack from single images. Example regex: 'Image_([0-9]*)_Z([0-9]*)_CH1.tif'. Default: \"\"\n</code></pre></p>"},{"location":"api/#image_preprocess","title":"<code>image_preprocess</code>","text":"<p>Restoration of imaging data with CUT model, as in Open-ST paper.</p> <p>Usage: <pre><code>openst image_preprocess [-h] [--h5-in H5_IN] [--image-in IMAGE_IN] [--image-out IMAGE_OUT] [--tile-size-px TILE_SIZE_PX] [--model MODEL] [--device {cpu,cuda}] [--num-workers NUM_WORKERS]\n\noptions:\n  -h, --help            show this help message and exit\n  --h5-in H5_IN         If set, image is loaded from the Open-ST h5 object (key in --image-in), and retored image is saved there (to the key --image-out). Default: \"\"\n  --image-in IMAGE_IN   Key or path to the input image. Default: \"\"\n  --image-out IMAGE_OUT\n                        Key or path where the restored image will be written into. Default: \"\"\n  --tile-size-px TILE_SIZE_PX\n                        The input image is split into squared tiles of side `--tile-size-px`, for inference.Larger values avoid boundary effects, but require more memory. Default: 512\n  --model MODEL         CUT model used for image restoration. Default: \"HE_CUT_rajewsky\"\n  --device {cpu,cuda}   Device used to run CUT restoration model. Can be ['cpu', 'cuda']. Default: \"cpu\"\n  --num-workers NUM_WORKERS\n                        Number of CPU workers for parallel processing. Default: -1\n</code></pre></p>"},{"location":"api/#spatial_stitch","title":"<code>spatial_stitch</code>","text":"<p>Stitch Open-ST h5 tile objects into a single Open-ST h5 object.</p> <p>Usage: <pre><code>openst spatial_stitch [-h] --tiles TILES [TILES ...] --tile-coordinates TILE_COORDINATES [--tile-id TILE_ID [TILE_ID ...]] [--tile-id-regex TILE_ID_REGEX] --h5-out H5_OUT [--tile-id-key TILE_ID_KEY]\n                             [--merge-output {same,unique,first,only}] [--join-output {inner,outer}] [--no-reset-index] [--no-transform] [--metadata METADATA]\n\noptions:\n  -h, --help            show this help message and exit\n  --tiles TILES [TILES ...]\n                        Path to h5 file, one per tile - separated by space\n  --tile-coordinates TILE_COORDINATES\n                        Path to the coordinate system file\n  --tile-id TILE_ID [TILE_ID ...]\n                        (Mandatory if --tile-id-regex is not specified) Per tile file specified in --tiles, each entry in --tile-id maps a tile file to the tile IDs under the first column of the --tile-\n                        coordinates file.\n  --tile-id-regex TILE_ID_REGEX\n                        (Mandatory if --tile-id is not specified) \"Regex to find tile id in file names, instead of specifying a list in --tile-id. Default: \"(L[1-4][a-b]_tile_[1-2][0-7][0-9][0-9])\"\n  --h5-out H5_OUT       Where the stitched spatial object will be written to\n  --tile-id-key TILE_ID_KEY\n                        Key of the h5 file (under /obs) where tile IDs are stored. If != 'tile_id', a new categorical column of this name will be generated for consistency. Default: \"tile_id\"\n  --merge-output {same,unique,first,only}\n                        how to merge tiles, can be \"same\", \"unique\", \"first\", \"only\". Default: \"same\"\n  --join-output {inner,outer}\n                        how to join tiles, can be \"inner\", \"outer\". Default: \"outer\"\n  --no-reset-index      If set, do not reset the obs_name index of the combined spatial object as 'obs_name:&lt;tile_id_key&gt;'; keep original 'obs_name'.\n  --no-transform        If set, spatial coordinates are not transformed - just combine tiles into a single spatial object\n  --metadata METADATA   (Optional) Path where the metadata will be stored. If not specified, metadata is not saved. Default: \"\"\n</code></pre></p>"},{"location":"api/#merge_modalities","title":"<code>merge_modalities</code>","text":"<p>Merges spatial locations (as points) and images of Open-ST data into a single h5 object.</p> <p>Usage <pre><code>openst merge_modalities [-h] --h5-in H5_IN --image-in IMAGE_IN [--image-key IMAGE_KEY]\n\noptions:\n  -h, --help            show this help message and exit\n  --h5-in H5_IN         Input Open-ST h5 object\n  --image-in IMAGE_IN   Image that will be loaded and written into the Open-ST h5 object\n  --image-key IMAGE_KEY\n                        Key in the Open-ST h5 object where the image will be saved. Default: \"uns/spatial/staining_image\"\n</code></pre></p>"},{"location":"api/#pairwise_aligner","title":"<code>pairwise_aligner</code>","text":"<p>Automatic pairwise alignment of transcript locations to imaging data.</p> <p>Usage: <pre><code>openst pairwise_aligner [-h] --h5-in H5_IN [--image-in IMAGE_IN] [--metadata METADATA] [--only-coarse] [--rescale-factor-coarse RESCALE_FACTOR_COARSE] [--threshold-counts-coarse THRESHOLD_COUNTS_COARSE]\n                               [--pseudoimage-size-coarse PSEUDOIMAGE_SIZE_COARSE] [--ransac-coarse-min-samples RANSAC_COARSE_MIN_SAMPLES] [--ransac-coarse-residual-threshold RANSAC_COARSE_RESIDUAL_THRESHOLD]\n                               [--ransac-coarse-max-trials RANSAC_COARSE_MAX_TRIALS] [--genes-coarse GENES_COARSE [GENES_COARSE ...]] [--rescale-factor-fine RESCALE_FACTOR_FINE]\n                               [--tissue-masking-gaussian-sigma TISSUE_MASKING_GAUSSIAN_SIGMA] [--fine-registration-gaussian-sigma FINE_REGISTRATION_GAUSSIAN_SIGMA]\n                               [--threshold-counts-fine THRESHOLD_COUNTS_FINE] [--pseudoimage-size-fine PSEUDOIMAGE_SIZE_FINE] [--ransac-fine-min-samples RANSAC_FINE_MIN_SAMPLES]\n                               [--ransac-fine-residual-threshold RANSAC_FINE_RESIDUAL_THRESHOLD] [--ransac-fine-max-trials RANSAC_FINE_MAX_TRIALS] [--fine-min-matches FINE_MIN_MATCHES]\n                               [--genes-fine GENES_FINE [GENES_FINE ...]] [--mask-tissue] [--keep-black-background] [--feature-matcher {LoFTR,SIFT,KeyNet}] [--fiducial-model FIDUCIAL_MODEL]\n                               [--num-workers NUM_WORKERS] [--device {cpu,cuda}]\n\noptions:\n  -h, --help            show this help message and exit\n\nData (required):\n  --h5-in H5_IN         Path to the merged Open-ST h5 object containing spatial coordinates and images\n\nData (optional):\n  --image-in IMAGE_IN   Key to the image used as the 'destination' during pairwise alignment. Default: \"uns/spatial/staining_image\"\n  --metadata METADATA   Path where the metadata will be stored. If not specified, metadata is not saved. Default: \"\"\n\nCoarse registration parameters:\n  --only-coarse         If selected, only the coarse alignment stage will run\n  --rescale-factor-coarse RESCALE_FACTOR_COARSE\n                        Rescaling factor for the input image (1:factor), used during coarse pairwise alignment. Default: 20\n  --threshold-counts-coarse THRESHOLD_COUNTS_COARSE\n                        Only spatial coordinates with counts larger than this number will be kept for pseudoimage rendering during coarse alignment. Default: 1\n  --pseudoimage-size-coarse PSEUDOIMAGE_SIZE_COARSE\n                        Size (in pixels) of the pseudoimage during coarse alignment. Default: 500\n  --ransac-coarse-min-samples RANSAC_COARSE_MIN_SAMPLES\n                        'min_samples' parameter of RANSAC, during coarse registration. Default: 3\n  --ransac-coarse-residual-threshold RANSAC_COARSE_RESIDUAL_THRESHOLD\n                        'residual_threshold' parameter of RANSAC, during coarse registration. Default: 2\n  --ransac-coarse-max-trials RANSAC_COARSE_MAX_TRIALS\n                        Times RANSAC will run (x1000 iterations) during coarse registration. Default: 2\n  --genes-coarse GENES_COARSE [GENES_COARSE ...]\n                        Genes used for plotting the pseudoimage during the coarse alignment phase. Default: None\n\nFine registration parameters:\n  --rescale-factor-fine RESCALE_FACTOR_FINE\n                        Rescaling factor for the input image (1:factor), used during fine pairwise alignment. Default: 10\n  --tissue-masking-gaussian-sigma TISSUE_MASKING_GAUSSIAN_SIGMA\n                        The gaussian blur sigma used during the isolation of the tissue on the HE (preprocessing). Default: 5\n  --fine-registration-gaussian-sigma FINE_REGISTRATION_GAUSSIAN_SIGMA\n                        Gaussian blur used on all modalities during fine registration. Default: 2\n  --threshold-counts-fine THRESHOLD_COUNTS_FINE\n                        Only spatial coordinates with counts larger than this number will be kept for pseudoimage rendering during fine alignment. Default: 0\n  --pseudoimage-size-fine PSEUDOIMAGE_SIZE_FINE\n                        Size (in pixels) of the pseudoimage during fine alignment. Default: 2000\n  --ransac-fine-min-samples RANSAC_FINE_MIN_SAMPLES\n                        'min_samples' parameter of RANSAC, during fine registration. Default: 3\n  --ransac-fine-residual-threshold RANSAC_FINE_RESIDUAL_THRESHOLD\n                        'residual_threshold' parameter of RANSAC, during fine registration. Default: 2\n  --ransac-fine-max-trials RANSAC_FINE_MAX_TRIALS\n                        Times RANSAC will run (x1000 iterations) during fine registration. Default: 2\n  --fine-min-matches FINE_MIN_MATCHES\n                        Minimum number of matching keypoints between modalities during fine alignment. Default: 50\n  --genes-fine GENES_FINE [GENES_FINE ...]\n                        Genes used for plotting the pseudoimage during the fine alignment phase. Default: None\n\nImage preprocessing parameters:\n  --mask-tissue         Tissue (imaging modality) is masked from the background for the feature detection\n  --keep-black-background\n                        Whether to set the background of the imaging modalities to white, after tissue masking\n\nFeature model parameters:\n  --feature-matcher {LoFTR,SIFT,KeyNet}\n                        Feature matching algorithm. Default: \"LoFTR\"\n  --fiducial-model FIDUCIAL_MODEL\n                        Path to a object detection model (YOLO) to detect fiducial markers. Default: \"\"\n\nComputational parameters:\n  --num-workers NUM_WORKERS\n                        Number of CPU workers for parallel processing. Default: 1\n  --device {cpu,cuda}   Device used to run feature matching model. Can be ['cpu', 'cuda']. Default: \"cpu\"\n</code></pre></p>"},{"location":"api/#apply_transform","title":"<code>apply_transform</code>","text":"<p>Apply a precomputed transformation matrix to the specified coordinates of an Open-ST h5 object</p> <p>Usage: <pre><code>openst apply_transform [-h] --keypoints-in KEYPOINTS_IN --h5-in H5_IN [--per-tile] [--spatial-key-in SPATIAL_KEY_IN] [--spatial-key-out SPATIAL_KEY_OUT]\n\noptions:\n  -h, --help            show this help message and exit\n  --keypoints-in KEYPOINTS_IN\n                        Path to the json file containing keypoints.\n  --h5-in H5_IN         Path to the input h5ad file containing spatial coordinates\n  --per-tile            (Optional) If set, transformations are applied per tile, from their keypoints. Otherwise, a single transform is computed for all tiles.\n  --spatial-key-in SPATIAL_KEY_IN\n                        Key of the Open-ST h5 object where the input spatial coordinates are read from. Default: \"obsm/spatial_pairwise_aligned_coarse\"\n  --spatial-key-out SPATIAL_KEY_OUT\n                        Key of the Open-ST h5 object where the transformed spatial coordinates are written into. Default: \"obsm/spatial_pairwise_aligned_fine\"\n</code></pre></p>"},{"location":"api/#manual_pairwise_aligner","title":"<code>manual_pairwise_aligner</code>","text":"<p>GUI for manual alignment of Open-ST data</p> <pre><code>openst manual_pairwise_aligner [-h] [--h5-in H5_IN] [--spatial-key SPATIAL_KEY] [--image-key IMAGE_KEY]\n\noptions:\n  -h, --help            show this help message and exit\n  --h5-in H5_IN         Path to the input h5ad file containing spatial coordinates. Default: \"\"\n  --spatial-key SPATIAL_KEY\n                        Path in the h5ad file to the spatial coordinates. Default: \"\"\n  --image-key IMAGE_KEY\n                        Path in the h5ad file to the image. Default: \"\"\n</code></pre>"},{"location":"api/#segment","title":"<code>segment</code>","text":"<p>Image (or pseudoimage)-based segmentation with cellpose and (optional) radial extension</p> <p>Usage: <pre><code>openst segment [-h] [--image-in IMAGE_IN] [--h5-in H5_IN] --mask-out MASK_OUT [--rna-segment] [--model MODEL] [--flow-threshold FLOW_THRESHOLD] [--cellprob-threshold CELLPROB_THRESHOLD]\n                      [--diameter DIAMETER] [--chunk-size CHUNK_SIZE] [--chunked] [--max-image-pixels MAX_IMAGE_PIXELS] [--device {cpu,cuda}] [--dilate-px DILATE_PX] [--outline-px OUTLINE_PX] [--mask-tissue]\n                      [--tissue-masking-gaussian-sigma TISSUE_MASKING_GAUSSIAN_SIGMA] [--keep-black-background] [--rna-segment-spatial-coord-key RNA_SEGMENT_SPATIAL_COORD_KEY]\n                      [--rna-segment-input-resolution RNA_SEGMENT_INPUT_RESOLUTION] [--rna-segment-render-scale RNA_SEGMENT_RENDER_SCALE] [--rna-segment-render-sigma RNA_SEGMENT_RENDER_SIGMA]\n                      [--rna-segment-output-resolution RNA_SEGMENT_OUTPUT_RESOLUTION] [--num-workers NUM_WORKERS] [--metadata METADATA]\n\noptions:\n  -h, --help            show this help message and exit\n  --image-in IMAGE_IN   Key in the Open-ST h5 object (when --h5-in is specified) or path to the file where the mask will be loaded from\n  --h5-in H5_IN         If specified, image is loaded from h5 (from key --image-in). Segmentation mask is saved there (to --mask-out). Default: \"\"\n  --mask-out MASK_OUT   Key in the Open-ST h5 object (when --h5-in is specified) or path to the file where the mask will be written into\n  --rna-segment         Performs segmentation based on local RNA density pseudoimages from sequencing data, instead of using a staining image. This assumes coordinates in microns (can be transformed with\n                        --rna-segment-input-resolution)\n  --model MODEL         cellpose model - either a path or a valid string to pretrained model. Default: \"\"\n  --flow-threshold FLOW_THRESHOLD\n                        cellpose's 'flow_threshold' parameter. Default: 0.5\n  --cellprob-threshold CELLPROB_THRESHOLD\n                        cellpose's 'cellprob_threshold' parameter. Default: 0\n  --diameter DIAMETER   cellpose's 'diameter' parameter. Default: 20\n  --chunk-size CHUNK_SIZE\n                        When prediction of the mask runs in separate chunks, this is the chunk square size (in pixels). Default: 512\n  --chunked             If set, segmentation is computed at non-overlapping chunks of size '--chunk-size'\n  --max-image-pixels MAX_IMAGE_PIXELS\n                        Upper bound for number of pixels in the images (prevents exception when opening very large images). Default: 933120000\n  --device {cpu,cuda}   Device used to run the segmentation model. Can be ['cpu', 'cuda']. Default: \"cpu\"\n  --dilate-px DILATE_PX\n                        Pixels the outlines of the segmentation mask will be extended. Default: 10\n  --outline-px OUTLINE_PX\n                        Objects will be represented as px-width outlines (only if &gt;0). Default: 0\n  --mask-tissue         Tissue (imaging modality) is masked from the background before segmentation.\n  --tissue-masking-gaussian-sigma TISSUE_MASKING_GAUSSIAN_SIGMA\n                        The gaussian blur sigma used during the isolation of the tissue on the staining image. Default: 5\n  --keep-black-background\n                        Whether to set the background of the imaging modalities to white after tissue masking\n  --rna-segment-spatial-coord-key RNA_SEGMENT_SPATIAL_COORD_KEY\n                        Path to the spatial coordinates inside the spatial object (e.g., 'obsm/spatial'). Default: \"obsm/spatial\"\n  --rna-segment-input-resolution RNA_SEGMENT_INPUT_RESOLUTION\n                        Spatial resolution of the input coordinates (retrieved from --rna-segment-spatial-coord-key). If it is in microns, leave as 1. If it is in pixels, specify the pixel to micron conversion\n                        factor. Default: 1\n  --rna-segment-render-scale RNA_SEGMENT_RENDER_SCALE\n                        Size of bins for computing the binning (in microns). For Open-ST v1, we recommend a value of 2. Default: 2\n  --rna-segment-render-sigma RNA_SEGMENT_RENDER_SIGMA\n                        Smoothing factor applied to the RNA pseudoimage (higher values lead to smoother images). Default: 1\n  --rna-segment-output-resolution RNA_SEGMENT_OUTPUT_RESOLUTION\n                        Final resolution (micron/pixel) for the segmentation mask. Default: 0.6\n  --num-workers NUM_WORKERS\n                        Number of CPU workers when --chunked is specified. Default: -1\n  --metadata METADATA   Path where the metadata will be stored. If not specified, metadata is not saved. Warning: a report (via openst report) cannot be generated without metadata! Default: \"\"\n</code></pre></p>"},{"location":"api/#segment_merge","title":"<code>segment_merge</code>","text":"<p>Merge two segmentation masks into one</p> <p>Usage: <pre><code>openst segment_merge [-h] --h5-in H5_IN --mask-in MASK_IN MASK_IN --mask-out MASK_OUT [--chunk-size CHUNK_SIZE] [--chunked] [--num-workers NUM_WORKERS]\n\noptions:\n  -h, --help            show this help message and exit\n  --h5-in H5_IN         If set, masks are loaded from the Open-ST h5 object (key in --mask-in), and segmentation is saved there (to the key under --mask-out). Default: \"\"\n  --mask-in MASK_IN MASK_IN\n                        Path to the input segmentation masks - two of them!\n  --mask-out MASK_OUT   Path (file or h5) where the merged mask will be saved\n  --chunk-size CHUNK_SIZE\n                        When prediction of the mask runs in separate chunks, this is the chunk square size (in pixels). Default: 512\n  --chunked             If set, segmentation is computed at non-overlapping chunks of size '--chunk-size'\n  --num-workers NUM_WORKERS\n                        Number of CPU workers when --chunked is specified. Default: -1\n</code></pre></p>"},{"location":"api/#transcript_assign","title":"<code>transcript_assign</code>","text":"<p>Aggregate transcripts into segmented cells.</p> <p>Usage:</p> <pre><code>openst transcript_assign [-h] --h5-in H5_IN --mask-in MASK_IN --spatial-key SPATIAL_KEY --h5-out H5_OUT [--mask-from-file] [--max-image-pixels MAX_IMAGE_PIXELS] [--shuffle-umi] [--metadata METADATA]\n\noptions:\n  -h, --help            show this help message and exit\n  --h5-in H5_IN         Path to an already aligned Open-ST h5 object\n  --mask-in MASK_IN     Path to image mask - a key in the Open-ST h5 object. Or, can be an image stored separately in the filesystem (when --mask-from-file is specified) Image data and ST coordinates must be\n                        pairwise aligned (implicit for the case of RNA-based segmentation)\n  --spatial-key SPATIAL_KEY\n                        Key in the Open-ST h5 object where the aligned coordinates are stored, e.g. 'spatial_pairwise_aligned_coarse' (after using 'openst pairwise_aligner')\n  --h5-out H5_OUT       Path where the segmented Open-ST h5 object will be written into\n  --mask-from-file      If set, the image mask is loaded from an external file\n  --max-image-pixels MAX_IMAGE_PIXELS\n                        Upper bound for number of pixels in the images (prevents exception when opening very large images). Default: 933120000\n  --shuffle-umi         If set, UMI locations will be shuffled. This can be used as a baseline for feature selection.\n  --metadata METADATA   Path where the metadata will be stored. If not specified, metadata is not saved. Warning: a report (via openst report) cannot be generated without metadata! Default: \"\"\n</code></pre>"},{"location":"api/#pseudoimage","title":"<code>pseudoimage</code>","text":"<p>Generate pseudoimages of Open-ST RNA data and visualize using napari.</p> <p>Usage: <pre><code>openst pseudoimage [-h] --h5-in H5_IN [--spatial-coord-key SPATIAL_COORD_KEY] [--input-resolution INPUT_RESOLUTION] [--render-scale RENDER_SCALE] [--render-sigma RENDER_SIGMA]\n                          [--output-resolution OUTPUT_RESOLUTION]\n\noptions:\n  -h, --help            show this help message and exit\n  --h5-in H5_IN         Necessary to create the pseudoimage\n  --spatial-coord-key SPATIAL_COORD_KEY\n                        Path to the spatial coordinates inside the spatial object (e.g., 'obsm/spatial')\n  --input-resolution INPUT_RESOLUTION\n                        Spatial resolution of the input coordinates (retrieved from --spatial-coord-key). If it is in microns, leave as 1. If it is in pixels, specify the pixel to micron conversion factor. Default: 1\n  --render-scale RENDER_SCALE\n                        Size of bins for computing the binning (in microns). For Open-ST v1, we recommend a value of 2. Default: 2\n  --render-sigma RENDER_SIGMA\n                        Smoothing factor applied to the RNA pseudoimage (higher values lead to smoother images). Default: 1\n  --output-resolution OUTPUT_RESOLUTION\n                        Final resolution (micron/pixel) for the pseudoimage. Default: 0.6\n</code></pre></p>"},{"location":"api/#preview","title":"<code>preview</code>","text":"<p>Preview locations (as points) and images of Open-ST data.</p> <p>Usage: <pre><code>openst preview [-h] --h5-in H5_IN [--file-structure] [--spatial-coord-keys SPATIAL_COORD_KEYS [SPATIAL_COORD_KEYS ...]] [--image-keys IMAGE_KEYS [IMAGE_KEYS ...]]\n                      [--pseudoimage-keys PSEUDOIMAGE_KEYS [PSEUDOIMAGE_KEYS ...]] [--spatial-coord-resampling SPATIAL_COORD_RESAMPLING [SPATIAL_COORD_RESAMPLING ...]]\n                      [--image-resampling IMAGE_RESAMPLING [IMAGE_RESAMPLING ...]] [--pseudoimage-units-to-um PSEUDOIMAGE_UNITS_TO_UM [PSEUDOIMAGE_UNITS_TO_UM ...]]\n\noptions:\n  -h, --help            show this help message and exit\n  --h5-in H5_IN         Necessary to create the pseudoimage\n  --file-structure      If set, will not open a visualization screen but will return the tree structure of the h5 file\n  --spatial-coord-keys SPATIAL_COORD_KEYS [SPATIAL_COORD_KEYS ...]\n                        Path to the spatial coordinates inside the spatial object (e.g., 'obsm/spatial'). Can be one or many (separated by space)\n  --image-keys IMAGE_KEYS [IMAGE_KEYS ...]\n                        Path to the image to be visualized. Can be one or many (separated by space)\n  --pseudoimage-keys PSEUDOIMAGE_KEYS [PSEUDOIMAGE_KEYS ...]\n                        Path to the spatial coordinates inside the spatial object to visualize as pseudoimage. Can be one or many (separated by space)\n  --spatial-coord-resampling SPATIAL_COORD_RESAMPLING [SPATIAL_COORD_RESAMPLING ...]\n                        Will load every n-th point. Can be one (same for all spatial-coords) or many (1-to-1 mapping to the spatial-coord list). Default: [1]\n  --image-resampling IMAGE_RESAMPLING [IMAGE_RESAMPLING ...]\n                        Will load every n-th pixel. Can be one (same for all images) or many (1-to-1 mapping to the image list). Default: [1]\n  --pseudoimage-units-to-um PSEUDOIMAGE_UNITS_TO_UM [PSEUDOIMAGE_UNITS_TO_UM ...]\n                        Conversion factor from spatial units to micron, before rendering the pseudoimage. Can be one (same for all images) or many (1-to-1 mapping to the image list). Default: [1.0]\n</code></pre></p>"},{"location":"api/#report","title":"<code>report</code>","text":"<p>Generate HTML reports from metadata files (json).</p> <p>Usage: <pre><code>openst report [-h] --metadata METADATA --html-out HTML_OUT\n\noptions:\n  -h, --help           show this help message and exit\n  --metadata METADATA  Path to the metadata file (json)\n  --html-out HTML_OUT  Path where the output HTML file will be created\n</code></pre></p>"},{"location":"api/#from_spacemake","title":"<code>from_spacemake</code>","text":"<p>Run openst commands using spacemake file structure. You need to specify one <code>subcommand</code> from above, with the respective arguments.</p> <p>Usage:</p> <pre><code>openst from_spacemake [-h] --project-id PROJECT_ID --sample-id SAMPLE_ID [--run-mode RUN_MODE] subcommand [params]\n\noptions:\n  -h, --help            show this help message and exit\n  --project-id PROJECT_ID\n                        From spacemake's project_df, this is the project_id string\n  --sample-id SAMPLE_ID\n                        From spacemake's project_df, this is the sample_id string\n  --run-mode RUN_MODE   When a sample has multiple run_mode(s), you must specify one\n</code></pre> <p>This command populates the arguments for the subcommands automatically. In the table below, you can find which of this arguments are populated automatically. <code>...</code> indicates that the value will change depending on the <code>--project-id</code> and <code>--sample-id</code> configuration.</p> subcommand populated arguments <code>spatial_stitch</code> <code>--h5-out ... --tiles ... --tile-id ...</code> <code>image_stitch</code> <code>--image-indir ... --image-out ...</code> <code>segment_merge</code> <code>--h5-in ... --mask-out uns/spatial/staining_image_mask_merged</code> <code>segment</code> <code>--h5-in ... --image-in uns/spatial/staining_image --mask-out uns/spatial/staining_image_mask</code> <code>transcript_assign</code> <code>--h5-in ... --mask-in uns/spatial/staining_image_mask --h5-out ...</code> <code>merge_modalities</code> <code>--h5-in ... --image-in ...</code> <code>manual_pairwise_aligner</code> <code>--h5-in ...</code> <code>apply_transform</code> <code>--h5-in ...</code> <code>pseudoimage</code> <code>--h5-in ...</code> <code>preview</code> <code>--h5-in ...</code> <code>pairwise_aligner</code> <code>--h5-in ...</code> <p>Note</p> <p>You can override any of these values by providing them explicitly.</p>"},{"location":"faq/","title":"FAQs","text":"<p>Do you have questions about the experimental or computational aspects of Open-ST? We do our best to answer all of your questions on this page. If you can't find your question  below, ask it on our discussion board!</p>"},{"location":"faq/#tissue-handling-and-sectioning","title":"Tissue handling and sectioning","text":"<p>What is the recommended freezing and embedding process?</p> <p>Open-ST requires the use of unfixed fresh-frozen tissue, embedded in OCT. An optimal embedding process is required to avoid the formation of freezing artifacts. The best results are achieved when tissue is frozen in a fast and uniform way. We recommend following 10X Visium's protocol for simultaneous freezing and embedding in their Tissue Preparation guide</p> <p>However, is also possible to embed already snap-frozen tissue in OCT using powdered dry ice, or an isopentane bath in liquid nitrogen or dry ice. In this case, be aware of:</p> <ul> <li>Once tissue is frozen avoid melting of the tissue when embedding in OCT.</li> <li>Do not immerge the tissue directly into liquid nitrogen (it will burn the edges!).</li> <li>Keep the embedding mold bases fully covered by dry ice or the cold isopentane bath to allow homogeneous freezing.</li> </ul> <p>What tissue section thickness is recommended?</p> <p>We section the tissue at a thickness of 10 um. This can be adapted if neccessary, but permeabilization time may change consequently. Thicker sectioning may also increase contamination from the cytoplasm of other cells in the z-plane.</p> <p>What cutting temperature is recommended?</p> <p>The optimal cutting temperature depends on the tissue being sectioned. As a starting point, page 91 in this reference by Epredia is helpful.</p>"},{"location":"faq/#sample-handling","title":"Sample handling","text":"<p>Are technical replicates required?</p> <p>As we have observed a high reproducibility across technical replicates (consecutive sections), technical replicates are not essential.</p> <p>How many sections (conditions/sample types) can be processed at once?</p> <p>Multiple samples can be processed at once with the use of a multiwell chamber hybridization cassette (such as this one by ArrayJet (product code: 206862)) (ArrayJet, accessed 13.11.2023). </p> <p>This cassette has sixteen 7 x 7 mm wells, each fitting one capture area; thus, allowing 16 samples or conditions to be processed simultaneously. We recommend handling a maximum of 15 capture areas per person for protocol steps 3.1 to 3.5 (until overnight incubation for reverse transcription).</p> <p>Moreover, Open-ST libraries are indexed on the p7-adapter side, allowing multiplexing of samples within one NGS run. </p> <p>What are the best practices to avoid cross-contamination?</p> <p>In order to avoid any RNA contamination is important to wipe down the cryostat and any tools used (brushes, tweezers) with 80%-100% ethanol before sectioning. Additionaly, change the blade and wipe down the cryostat and tools in between sectioning different samples. </p> <p>What pepsin incubation times should I test?</p> <p>It is important to set the permeabilization condition for each tissue type.  We recommend to test at least a range including 15 min, 30 min, and 60 min with two different concentration (0.7 and 1.4 U/\u03bcL). </p> <p>It is preferable to chose the minimum incubation time/ enzyme concentration that gives the maximum RNA capture (see Permeabilization).</p> <p>What tissues have already been tested with Open-ST?</p> <p>Several tissues have been tested using Open-ST, including in-vitro 3D-cultures. Here, we list the tested tissues with the permeabilization condition used:</p> HumanMouse Tissue type Permeabilization condition (time, pepsin concentration) Metastatic lymph node 45 min, 1.4 U/\u03bcL Healthy  lymph node 45 min, 1.4 U/\u03bcL Head and neck squamous cell carcinoma 45 min, 1.4 U/\u03bcL iPSC-derived Brain Organoids 15 - 30 min, 0.7 U/\u03bcL Tissue type Permeabilization conditions Mouse head (embryo E13) 30 min, 0.7 U/\u03bcL Mouse brain 30 min, 0.7 U/\u03bcL"},{"location":"faq/#capture-area","title":"Capture area","text":"<p>Can you store capture area pieces?</p> <p>Yes. We have successfully generated libraries from capture areas stored &gt;12 months. We recommend storage at -20\u00b0C or -80\u00b0C with silica beads. </p> <p>Can tissue sections be placed on a capture area and stored before library preparation?</p> <p>Yes. We have stored capture areas with tissue sections for 1 week at -80\u00b0C before proceeding with library preparation and have not observed an effect mRNA capture (qPCR). </p> <p>Sections on capture areas were stored before methanol fixation. Once the tissue was placed on the capture area, care was taken to keep it frozen until library preparation.</p> <p>Longer storage may be possible, but has not been systematically tested. </p>"},{"location":"faq/#general-protocol","title":"General protocol","text":"<p>What instruments/equipment is required to perform the Open-ST protocol?</p> <p>Open-ST was developed with the idea to make it accessible to any laboratory. It requires standard lab equipment: </p> <ul> <li>Capture area generation: Illumina\u00ae NovaSeq6000, 3D-printer (capture areas can be made without a 3D-printed cutting guide, if this is not available. A cutting guide is recommended for ease-of-use, preventing scratches and irregular capture areas)  </li> <li>Library preparation: Cryostat, hybridization oven, thermocycler, Bluepippin or PippinHT (alternatively, agarose gel and DNA extraction can be done manually)</li> <li>Imaging: Brightfield microscope / Fluorescence microscope </li> <li>Quality control: Qubit, qPCR, automated gel electrophoresis (Bioanalyzer, TapeStation, Fragment analyzer)</li> <li>Sequencing: various sequencers can be used, as long as a minimum of 100 cylces can be sequenced (ex., Illumina\u00ae NextSeq500/550, NextSeq2000, NovaSeq6000, NovaSeqX(plus))</li> </ul>"},{"location":"faq/#imaging","title":"Imaging","text":"<p>Are immunohistochemical (IHC) or immunofluorescence (IF) stainings compatible with Open-ST?</p> <p>IHC/IF staining may reduce the quality of the resulting Open-ST library, since staining occurs before RNA capture and may lead to RNA degradation.  </p> <p>We have successfully applied hematoxilin and eosin (H&amp;E) staining, as well as fluorescent cytoskeletal (Phalloidin) and nuclei (DAPI) staining, as part of the Open-ST workflow.</p>"},{"location":"faq/#library-preparation-and-sequencing","title":"Library preparation and sequencing","text":"<p>How does a good library profile look like before and after size selection?</p> <p>A good library profile is smooth without any short fragment peaks or evident peaks inside the library range. If small length peaks remain after library size selection, they should be removed with an additional size selection (agarose gel or beads). </p> <p>Evident peaks inside the library range could be due to over-amplification of a low complexity library. If possible, we recommend checking previous protocol steps, including RNA quality control, permeabilization condition, amplification cycling number.</p> <p>What is the recommended sequencing depth?</p> <p>Sequencing depth requirements vary with tissue section size, coverage of capture area and experimental goals. For reference, for a 3x4 mm section we obtain a median of around 900 UMIs per cell when investing 500 million sequencing reads. Shallow sequencing can always be performed first to assess general library quality (%spatial mapping, % uniquely mapping to genome, % rRNA, % mt-encoded). </p>"},{"location":"faq/#pairwise-alignment","title":"Pairwise alignment","text":"<p>The fiducial marks cannot be detected/are not visible</p> <p>Sometimes, fiducial marks might not be visible when imaging thick tissue (we have noticed this with &gt; 10 \u00b5m thickness) or under areas with high cellular density. Thus, automatic coarse alignment will work, but the fine alignment might fail, as the model cannot find these markers in the image. </p> <p>We recommend using the GUI to automatically select keypoints between the two modalities. If more than 2 are visible per tile, we recommend selecting the fiducial markers manually. If these are not visible, you can select alternative keypoints (i.e., morphological features that look similar between the ST and staining image modalities). </p> <p>In the latter case, we cannot ensure that the alignment accuracy will lead to subcellular resolution, which is diagnosed with the distance from fiducials across modalities.</p> <p>In manual alignment mode, how many fiducials/features should I select per tile?</p> <p>Given that a rigid transformation model is estimated from the selected pairs of keypoints, we recommend at least 2 points. The more corresponding points are selected, the better.</p>"},{"location":"faq/#image-segmentation","title":"Image segmentation","text":"<p>The segmentation did not perform well</p> <p>We provide an interface to the default, pre-trained cellpose models, as well as our fine-tuned HE_cellpose_rajewsky model. We have tested this on a wide diversity of tissues, but it is possible that different microscopy setups and imaged tissues deliver different segmentation performance. </p> <p>Especially, tissues with higher cellular densities and lower contrast between background/nuclei (or cells) might perform worse. Thus, we recommend referring to the cellpose tutorial on how to train your own model.</p>"},{"location":"introduction/","title":"Introduction","text":"<p>Welcome! Here, we provide comprehensive resources to help you generate and analyse Open-ST data in your lab.</p> <p>Open-ST is a spatial transcriptomics method that enables efficient whole-transcriptome capture at subcellular resolution. In our paper, we have demonstrated Open-ST's wide applicability, showing robust transcriptome capture across various mouse and human tissues.  Our method is cost-efficient, straightforward to employ, and includes open-source software for seamless data processing and analysis.</p> <p>Here, you can find detailed step-by-step descriptions of the experimental and the computational workflows. In a FAQ section we address commonly asked questions. Via our discussion board and our chat, you can submit your own questions, and we will do our best to provide answers. </p> <p>Also on this website, we showcase example datasets. </p>"},{"location":"computational/generate_expression_matrix/","title":"Segmentation and single-cell quantification","text":"<p>Once the ST and imaging modalities have been aligned,  you can segment the images into single cells/nuclei, and then aggregate the spot locations into individual cells  for subsequent analysis.</p>"},{"location":"computational/generate_expression_matrix/#cell-segmentation-from-tissue-image","title":"Cell segmentation from tissue image","text":"<p>Let's create a new Open-ST h5 object containing a cell-by-gene expression matrix. First, you will need a cell  (or nuclear) segmentation mask.</p> <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     segment \\\n     --model HE_cellpose_rajewsky # default model for segmentation of H&amp;E images\n</code></pre> From (semi)automatic alignmentFrom manual alignment <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     segment \\\n     --model HE_cellpose_rajewsky \\\n     --image-in uns/spatial_pairwise_aligned/staining_image_transformed\n</code></pre> <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     segment \\\n     --model HE_cellpose_rajewsky\n</code></pre> <p>We segment cells (or nuclei) from staining images using cellpose. We provide a model that we fine-tuned for segmentation of fresh-frozen, H&amp;E-stained tissue, here, but you can use any other model (e.g., pretrained from cellpose, like <code>cyto2</code> or <code>nuclei</code>, or your own). Also, by default, segmentation is extended radially 10 pixels (see <code>--dilate-px</code>), to account for cytoplasm surrounding the nucleus as a first approximation of cell shape (might hold or not depending on the tissue).</p> I want to segment very small and very large cells... <p>You can perform an additional round of segmentation by, e.g., adjusting the diameter parameter.</p> <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     segment \\\n     --mask-out uns/spatial/staining_image_mask_large \\\n     --dilate-px 50 \\\n     --diameter 50 # diameter for the larger cell type\n</code></pre> <p>In this case, we changed <code>--mask-out</code> to a different key, so we can keep both masks inside the Open-ST h5 object.</p> <p>Then, you can combine the segmentation masks of both diameter configurations.  This command will apply an \"AND\" between all images, to only preserve mask of non-overlapping,  with the hierarchy provided in the <code>--image-in</code> argument (first has higher priority).</p> <pre><code>openst segment_merge \\\n     --h5-in spatial_stitched_spots.h5ad \\\n     --mask-in uns/spatial/staining_image_mask uns/spatial/staining_image_mask_large\n     --mask-out uns/spatial/staining_image_mask_combined\n</code></pre>"},{"location":"computational/generate_expression_matrix/#quality-control-of-segmentation","title":"Quality control of segmentation","text":"<p>You can assess the quality of segmentation with <code>openst preview</code>:</p> From (semi)automatic alignmentFrom manual alignment <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     preview \\\n     --image-key uns/spatial_pairwise_aligned/staining_image_transformed uns/spatial/staining_image_mask\n</code></pre> <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     preview \\\n     --image-key uns/spatial/staining_image uns/spatial/staining_image_mask\n</code></pre> <p>This will create a <code>napari</code> window with two image layers. Change the mask image layer into a label layer, which is designed for displaying each integer (ID from the segmentation mask) as a different random color, with background rendered as transparent.</p> <p>If you are satistied with the quality of the segmentation, you are all set to continue with single-cell quantification.</p>"},{"location":"computational/generate_expression_matrix/#single-cell-quantification","title":"Single-cell quantification","text":"<p>Then, you can create a single file containing the transcriptomic information aggregated into (segmented) single-cells.</p> From automatic alignmentFrom semiautomatic alignmentFrom manual alignment <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     transcript_assign \\\n     --spatial-key obsm/spatial_pairwise_aligned_fine \\\n     --mask-in uns/spatial_pairwise_aligned/staining_image_transformed\n</code></pre> <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     transcript_assign \\\n     --spatial-key obsm/spatial_manual_fine \\\n     --mask-in uns/spatial_pairwise_aligned/staining_image_transformed\n</code></pre> <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     transcript_assign \\\n     --spatial-key obsm/spatial_manual_fine\n</code></pre>"},{"location":"computational/generate_expression_matrix/#expected-output","title":"Expected output","text":"<p>After the steps above, you will have a single <code>h5ad</code> file with transcriptomic information per segmented cell, with spatial coordinates aligned to the staining image. The staining image and the segmented image are provided in this object, so it is possible to visualize it with squidpy or spatialdata, among other tools.</p> <p>Warning</p> <p>In the Open-ST h5 object, the cell with ID 0 will correspond to the background. Please remove it before  proceeding with analysis.</p> <p>This concludes the preprocessing of 2D spatial transcriptomics and imaging data of the Open-ST protocol. Next steps include 3D reconstruction, and downstream analysis of nD data.</p>"},{"location":"computational/getting_started/","title":"Getting started","text":"<p>After folowing the experimental protocol, we provide the <code>openst</code> python package for transforming the raw sequencing data into objects that can be used for spatial, single-cell analysis, in five steps:</p> <ol> <li>Preprocessing of Open-ST spatial barcodes (capture area)</li> <li>Preprocessing of Open-ST transcriptomic library</li> <li>Pairwise alignment: the spatial coordinates of transcriptomics data are aligned     to tissue imaging.</li> <li>Segmentation and single-cell quantification: transcriptomic data     are aggregated into single cells using the information from cell segmentation of tissue images.</li> <li>3D reconstruction of tissue imaging and transcriptome from serial sections.    We provide tutorials for interactive visualization of 3D data.</li> </ol>"},{"location":"computational/getting_started/#installation","title":"Installation","text":""},{"location":"computational/getting_started/#with-pip-recommended","title":"with pip, recommended","text":"<p>The computational tools of the Open-ST workflow are published as a Python package and can be installed with <code>pip</code>, ideally by using a virtual environment. Open up a terminal and install <code>openst</code> with:</p> <pre><code>pip install openst\n</code></pre> <p>Tip</p> <p>If you don't have prior experience with Python, we recommend reading Using Python's pip to Manage Your Projects' Dependencies, which is a really good introduction on the mechanics of Python package management and helps you troubleshoot if you run into errors.</p> <p>Running on Apple Silicon-based Macs</p> <p>If you have a Mac with Apple Silicon (M1 or later), please install <code>openst</code> on a Rosetta environment  to ensure full compatibility (i.e., <code>openst manual_pairwise_aligner</code> might not work otherwise).  Also, the version of scikit-image pinned in the requirements might not be available for Apple Silicon.  Thus, create an environment and install dependencies as follows (assuming you have installed <code>conda</code>):</p> <pre><code>CONDA_SUBDIR=osx-64 conda create -n openst python=3.11\nconda install scikit-image==0.19.3\npip install openst\n</code></pre> <p>When running <code>openst manual_pairwise_aligner</code> for the first time, startup time will be longer than usual. This is the expected behavior with osx-64 binaries (Rosetta). Also, you can install the optional <code>napari</code> (used in <code>openst preview</code>):</p> <pre><code>pip install napari\n</code></pre> Installed on Linux, accessing via SSH from Windows or macOS <p>If you install <code>openst</code> on Linux, and then use SSH from Windows or macOS to run it, you will need to have X11 redirection for the GUI-based components (i.e., <code>manual_pairwise_aligner</code> and <code>preview</code>).</p> <p>For example, you have to run SSH as: <pre><code>ssh -X user@server\n</code></pre></p> <p>If you are using macOS, please download and install X-quartz.</p> <p>If you are using Windows, we recommend using Tabby as the terminal, then  VcXsrv as the X Server. You will need to setup a new SSH Profile with  X11 forwarding in Tabby.</p>"},{"location":"computational/getting_started/#from-git","title":"from git","text":"<p><code>openst</code> can be directly installed from the source GitHub repository: <pre><code>git clone https://github.com/rajewsky-lab/openst.git\npip install -e openst\n</code></pre></p>"},{"location":"computational/getting_started/#with-docker","title":"with docker","text":"<p>The official Docker image is a great way to get up and running in a few minutes, as it comes with all dependencies pre-installed. Open up a terminal and pull the image:</p> <pre><code>docker pull rajewsky/openst\n</code></pre>"},{"location":"computational/getting_started/#get-a-bash-terminal","title":"Get a <code>bash</code> terminal","text":"<p>In a terminal: <pre><code>docker run -it --rm --entrypoint bash openst\n</code></pre></p>"},{"location":"computational/getting_started/#attach-a-local-folder-to-docker","title":"Attach a local folder to <code>docker</code>:","text":"<p>In a terminal: <pre><code>docker run -it --rm -v local_folder:/app/docker_folder --entrypoint bash openst\n</code></pre></p> <p>Make sure to replace <code>local_folder</code> (and optionally <code>docker_folder</code>).</p>"},{"location":"computational/getting_started/#support-gui-openst-manual_pairwise_aligner-or-napari","title":"Support GUI (<code>openst manual_pairwise_aligner</code> or <code>napari</code>)","text":"<p>In a terminal: <pre><code>docker run -it --rm -p 9876:9876 openst\n</code></pre></p> <p>Then open https://localhost:9876 in a browser. The video below shows an example launching <code>openst manual_pairwise_aligner</code> on the browser (we recommend Google Chrome or similar).</p> <p>Running on Apple Silicon-based Macs</p> <p>If you have a Mac with Apple Silicon (M1 or later), you need to configure <code>docker run</code> as:</p> <p><pre><code>docker run --platform linux/amd64 # .. rest of the command\n</code></pre> This will use emulation of amd64 binaries, so performance might be slower than native. Please consider running on a Linux-based workstation, if possible, with a CUDA-supported GPU.</p>"},{"location":"computational/pairwise_alignment/","title":"Pairwise alignment","text":"<p>In the previous step, you processed and mapped transcriptomic reads into spatial coordinates with <code>spacemake</code>. Before aggregating transcriptomic information per cell, we need to align this transcriptomic data into tissue space, leveraging imaging data.</p> <p><code>openst</code> can automatically (or manually) perform pairwise alignment of transcriptomic and imaging modalities, via advanced computer vision algorithms. Alignment is performed in two steps:</p> <ol> <li>Coarse (low-resolution) of H&amp;E images to pseudoimages of ST data, to roughly align the transcriptome to the tissue.</li> <li>Fine (high-resolution), using fiducial marks detected at both modalities for sub-micron accurate alignment.</li> </ol>"},{"location":"computational/pairwise_alignment/#data-required","title":"Data required","text":"<p>Two data modalities are used for pairwise alignment: </p> <ol> <li>A single Open-ST h5 object (from <code>spacemake</code>) containing all the spatially-resolved locations of a sample.</li> <li>A single, high-resolution image of the capture area and tissue</li> </ol>"},{"location":"computational/pairwise_alignment/#tissue-transcriptome","title":"Tissue transcriptome","text":"<p>If you ran <code>spacemake</code> with a <code>puck</code> with a <code>coordinate_system</code>, and a <code>run_mode</code> without meshing, e.g.:</p> <pre><code>pucks:\n  openst:\n    coordinate_system: puck_data/openst_coordinate_system.csv\n    spot_diameter_um: 0.6\n    width_um: 1200\n...\nrun_modes:\n  openst:\n    clean_dge: false\n    count_intronic_reads: true\n    count_mm_reads: true\n    detect_tissue: false\n    mesh_data: false\n    mesh_type: 'hexagon'\n    n_beads: 100000\n    polyA_adapter_trimming: true\n    spatial_barcode_min_matches: 0.1\n</code></pre> <p>Then you are all set to proceed with the Tissue image preprocessing (unless you had the issues below).</p> My <code>run_mode</code> and/or <code>puck</code> do not look like that <p>It is likely that you didn't specify a <code>coordinate_system</code> or you only have <code>mesh</code>(ed) Open-ST h5 objects,  therefore you need to generate a <code>puck_collection</code> Open-ST h5 object, manually:</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo_project \\\n    --sample-id openst_demo_sample \\\n    spatial_stitch \\\n    --tile-coordinates fc_1_coordinate_system.csv\n</code></pre> <p>Please replace <code>--tile-coordinates</code> with the adequate coordinate_system for your barcoded flow cell. This one is available under the examples section</p> <p>If you want to select only specific tiles for a sample, e.g., to exclude some spurious tiles,  you can <code>puck_collection</code> files fully manually, without the <code>from_spacemake</code> command: </p> <pre><code>openst spatial_stitch \\\n    --tiles dge.fc_1_tile_2267.h5ad dge.fc_1_tile_2268.h5ad \\\n    --tile-id fc_1_tile_2267 fc_1_tile_2268 \\\n    --tile-coordinates fc_1_coordinate_system.csv \\\n    --h5-out spatial_stitched_spots.h5ad\n</code></pre>"},{"location":"computational/pairwise_alignment/#tissue-image","title":"Tissue image","text":"<p>The tissue transcriptome data you just preprocessed will be aligned into a tissue (hi-res) image. For this, <code>openst</code> expects a single, high-resolution <code>tiff</code> image where the tissue is visible (and preferrably at least a small part of the capture area, too).</p> <p>Expand one of the cases below to decide how to proceed with image data:</p> My microscope gives a single, hi-res image <p>Fantastic! Just copy it to the relevant <code>spacemake</code> subfolder for the specific project and sample,  for instance:</p> <pre><code>spacemake_folder\n`-- projects\n    `-- &lt;project_id&gt;\n        `-- processed_data\n            `-- &lt;sample_id&gt;\n                `-- imaging # you might need to create\n                    `-- Image_Stitched_Composite.tif # copy with this name\n</code></pre> <p>Make sure to copy the image to that location, with the name <code>Image_Stitched_Composite.tif</code>. <pre><code>projects/openst_demo_project/processed_data/openst_demo_sample/imaging/Image_Stitched_Composite.tif\n</code></pre></p> My microscope doesn't give a single image, but many tile files <p>When performing imaging, i.e. as tile-scans, you might need to assemble a single, large image from a collection of smaller tiles (fields-of-view, FOVs). </p> <p>We provide tools to perform tile stitching from raw data with the microscopy setup showcased in our implementation (a Keyence BZ-X710 inverted fluorescence phase contrast microscope). If you use a different microscope setup,  please refer to the documentation of your microscope for how to stitch tile-scans into a single image.</p> <p>For this keyence microscope, copy the raw data (including <code>*.tiff</code> and <code>.bcf</code> files) into the <code>spacemake</code> folder specific for that project and sample:</p> <pre><code>spacemake_folder\n`-- projects\n    `-- &lt;project_id&gt;\n        `-- raw_data\n            `-- imaging # you might need to create it\n                `-- &lt;sample_id&gt;\n                    |-- Image.bcf\n                    `-- *.tif\n</code></pre> <p>Then, run: <pre><code>openst image_stitch \\\n    --microscope='keyence' \\\n    --imagej-bin=&lt;path_to_fiji_or_imagej&gt; \\\n    --image-indir=projects/&lt;project_id&gt;/raw_data/imaging/&lt;sample_id&gt; \\\n    --image-out=projects/&lt;project_id&gt;/processed_data/&lt;sample_id&gt;/imaging/Image_Stitched_Composite.tif\n</code></pre></p> <p>This leverages the Grid/Collection stitching plugin included in Fiji  to create a single, composite tile-scan image. Replace <code>&lt;path_to_fiji_or_imagej&gt;</code> with the path where the Fiji executable is.</p> <p>Question</p> <p>If you don't know how to specify the <code>&lt;path_to_fiji_or_imagej&gt;</code>, please follow the official instructions provided for Running Headless. For example, under linux you can download it using</p> <pre><code>cd ~\nwget \"https://downloads.imagej.net/fiji/latest/fiji-linux64.zip\"\nunzip fiji-linux64.zip\n# then, &lt;path_to_fiji_or_imagej&gt; will be \"~/Fiji.app/ImageJ-linux64\"\n</code></pre> <p>Note</p> <p>If your imaging setup consisted of a Z-stack, each tile image will likely be a FOV and a specific Z plane  (e.g., file names like Image_00001_Z001.tif, Image_00001_Z002.tif,...). In this case, you can specify a  regular expression (regex) to parse the Z plane from the file names, and a single file per FOV  will be created before stitching. </p> <p>This can be specified in <code>openst image_stitch</code> with the argument <code>--join-zstack-regex</code> (empty, by default)</p> <p>Either way, <code>openst</code> expects a single <code>.tif</code> file at <code>projects/&lt;project_id&gt;/processed_data/&lt;sample_id&gt;/imaging/Image_Stitched_Composite.tif</code>.</p> <p>Unless you had the issue below...</p> The quality of images is suboptimal (e.g., for segmentation) <p>Most of the times, large tile-scans may have uneven illumination, focus or noise. This can be challenging for downstream processing, like segmentation, feature extraction or quantification (i.e., of fluorescence images).  There is a plethora of methods to address these issues (e.g., Flatfield Correction from BigStitcher, or CARE, to name some). This might be highly dependent on your microscope, imaging settings, sample type, sample width... Always look at your images so you can take an informed decision.</p> <p>In our publication, we leveraged a CUT model that allowed to homogeneize the style of the whole tile-scan - that is, reduce possible biases in illumination, noise and focus across the entire tile-scan. You can run this by running the following command on the stitched image.</p> <p></p> <pre><code>openst image_preprocess \\\n    --image-in Image_Stitched_Composite.tif \\\n    --image-out Image_Stitched_Composite_Restored.tif\n    # --device cuda # in case you have a CUDA-compatible GPU\n</code></pre> <p>If you ran <code>openst merge_modalities</code>, then imaging data will be contained inside the Open-ST h5 object, and the command can be adapted:</p> <pre><code>openst image_preprocess \\\n    --h5-in multimodal/spots_stitched.h5ad # just a placeholder, adapt\n    # --device cuda # in case you have a CUDA-compatible GPU\n</code></pre> <p>By default, the image will be loaded from the key <code>uns/spatial/staining_image</code>, and the CUT-restored image will be saved to <code>uns/spatial/staining_image_restored</code>. You can preview the image restoration results using:</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo_project \\\n    --sample-id openst_demo_sample \\\n    --image-key uns/spatial/staining_image uns/spatial/staining_image_restored\n</code></pre> <p>This will load the two images and visualize it using <code>napari</code>. Later, you can run segmentation and pairwise alignment using either the default merged image (<code>uns/spatial/staining_image</code>), or the restored image (<code>uns/spatial/staining_image_restored</code>). Always assess these preprocessing choices (quantitatively and qualitatively) to decide whether these make sense for your data.</p> <p>Once the single image has been generated, make sure that the image is the full-resolution and not a downsampled version. As a rule of thumb, at least a few fiducial markers must be clearly distinguishable.</p> <p>... you are all set to proceed with pairwise alignment.</p>"},{"location":"computational/pairwise_alignment/#merging-data-modalities","title":"Merging data modalities","text":"<p>Once the ST and imaging data have been stitched, you can create a single object containing both modalities:</p> <pre><code>openst from_spacemake \\\n     --project-id openst_demo_project \\\n     --sample-id openst_demo_sample \\\n     merge_modalities\n</code></pre>"},{"location":"computational/pairwise_alignment/#pairwise-alignment_1","title":"Pairwise alignment","text":"<p>From the merged object you created above, you can do pairwise alignment of the transcriptomic data into the tissue image automatically, semiautomatically, or fully manually:</p> Automatic (or semiautomatic) alignmentManual alignment <p>For aligning transcriptomic data into H&amp;E-stained tissue sections, we recommend leaving  the rest of arguments with default parameters - you can get a full list of configurable parameters by running <code>openst pairwise_aligner --help</code>.</p> <pre><code>openst from_spacemake \\\n      --project-id openst_demo_project \\\n      --sample-id openst_demo_sample \\\n      pairwise_aligner\n      # --metadata alignment.json # to create a visual report\n      # --only-coarse for semiautomatic\n</code></pre> <p>When running automatic alignment, the spatial keys will be: 1. <code>obsm/spatial</code>: the original (unaligned) coordinates 2. <code>obsm/spatial_pairwise_aligned_coarse</code>: after low-res alignment 3. <code>obsm/spatial_pairwise_aligned_fine</code>: after hi-res refinement</p> <p>Similarly, the aligned image will be saved under <code>uns/spatial_pairwise_aligned/staining_image_transformed</code>.</p> <p>Therefore, if you want to visualize with the GUI or perform manual fine-tuning of the alignment, you need to specify the correct <code>--spatial-key</code> and <code>--image-key</code>:</p> <pre><code># for visualization and/or manual fine-tuning\nopenst from_spacemake \\\n      --project-id openst_demo_project \\\n      --sample-id openst_demo_sample \\\n      manual_pairwise_aligner \\\n      --spatial-key obsm/spatial_pairwise_aligned_fine \\\n      --image-key uns/spatial_pairwise_aligned/staining_image_transformed\n\n# if you want to perform semiautomatic alignment,\n# continue with openst manual_pairwise_aligner\n# see \"Manual alignment\" tab\n</code></pre> <p>Also, in some of the following steps (e.g., segmentation), make sure to populate  the <code>--image-key</code> and <code>--spatial-key</code> arguments with the correct values.</p> <p>We provide a Graphical User Interface (GUI) for selecting keypoints between imaging &amp; ST modalities,  for full manual alignment or refinement of automatic results. This GUI requires a single Open-ST h5 object (after spatial stitching). There are two kinds of workflow:</p> <pre><code>openst from_spacemake \\\n      --project-id openst_demo_project \\\n      --sample-id openst_demo_sample \\\n      manual_pairwise_aligner \\\n      --spatial-key obsm/spatial \\\n      --image-key uns/spatial/staining_image\n</code></pre> <p>In the GUI, you first perform coarse alignment (not tile by tile), and then click 'Apply to data'. Save the transformed coordinates as <code>obsm/spatial_manual_coarse</code>. Then, re-render with with spatial key, select at least 3 corresponding keypoints per tile, and save a keypoints file, e.g., as <code>keypoints.json</code>.</p> <p>Then you can apply the transformation, per tile, separately:</p> <pre><code>openst from_spacemake \\\n      --project-id openst_demo_project \\\n      --sample-id openst_demo_sample \\\n      apply_transform \\\n      --keypoints-in keypoints.json \\\n      --spatial-key-in obsm/spatial_manual_coarse \\\n      --spatial-key-out obsm/spatial_manual_fine \\\n      --per-tile\n</code></pre> <p>This will save the refined (similar to automatic hi-res alignment) coordinates into <code>obsm/spatial_manual_fine</code>. The image data will still be (by default) under <code>uns/spatial/staining_image</code>. Make sure to populate <code>--image-key</code>  and <code>--spatial-key</code> arguments in later steps with the correct values.</p> <p>We provide a video tutorial showcasing the GUI, with an illustrative example  of refinement from (only coarse) automatic alignment.</p> <p> Walkthrough of the GUI for manual alignment by @danilexn \u2013  5m \u2013 Learn how to visualize and align STS and imaging data in a step-by-step guide.</p> <p>Now you are all set to proceed with the visual (qualitative) assessment of the alignment (unless you had the issues below).</p> The coarse (or fine) alignment didn't work <p>There are several parameters that you can change.</p> <p>The most important ones are:     - <code>--rescale-factor-coarse</code> or <code>--rescale-factor-fine</code>: the highest, the lower resolution the image; thus, more global features are used for registration     - <code>--threshold-counts-coarse</code> or <code>--threshold-counts-fine</code>: the highest, the less spots there will be on the image</p> <p>These allow to increase the number of matches and possibly the number of RANSAC inliers. There are other RANSAC-specific parameters that can be changed, such as <code>--ransac-coarse-residual-threshold</code>, <code>--ransac-coarse-max-trials</code> and <code>--ransac-fine-min-samples</code>. For more parameters, check <code>openst pairwise_aligner --help</code>.</p> I get an error: 'This application failed to start [...]' <p>In some environments, the following error might happen:</p> <pre><code>qt.qpa.plugin: Could not load the Qt platform plugin \"xcb\" in \"/home/user/miniconda3/envs/openst/lib/python3.11/site-packages/cv2/qt/plugins\" even though it was found.\n\nThis application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.\n\nAvailable platform plugins are: xcb, eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, webgl.\n</code></pre> <p>This can be solved by removing the files inside <code>/home/user/miniconda3/envs/openst/lib/python3.11/site-packages/cv2/qt/plugins</code>, e.g. see this StackOverflow thread</p>"},{"location":"computational/pairwise_alignment/#visual-assessment-of-alignment","title":"Visual assessment of alignment","text":""},{"location":"computational/pairwise_alignment/#with-html-report","title":"With HTML report","text":"<p>With automatic alignment, if you specified the <code>--metadata</code> argument, you can generate an HTML report showing a qualitative summary of the alignment (images, parameters...)</p> <pre><code>openst report --metadata=alignment.json --html-out=alignment_report.html\n</code></pre>"},{"location":"computational/pairwise_alignment/#with-interactive-gui","title":"With interactive GUI","text":"<p>Alternatively, you can visualize the images &amp; ST data interactively using the integrated interactive GUI.</p> <pre><code>openst manual_pairwise_aligner\n</code></pre> <p>We provide a Graphical User Interface (GUI) for selecting keypoints between imaging &amp; ST modalities,  for visualization and refinement of automatic results. This GUI requires a single Open-ST h5 object, the output of <code>openst pairwise_aligner</code>.</p>"},{"location":"computational/pairwise_alignment/#expected-output","title":"Expected output","text":"<p>After automatic or manual alignment, you will have a single <code>h5ad</code> file, containing the transformed spatial coordinates. This will be used in the following step to aggregate the transcripts by a spatially-corresponding cell, in order to get a cell-by-gene matrix that can be used in later downstream analysis.</p>"},{"location":"computational/preprocessing_capture_area/","title":"Preprocessing capture area library","text":"<p>After sequencing the Open-ST capture areas, you will get basecall files in <code>bcl</code> format, or raw reads in <code>fastq</code> format (see sequence file formats from Illumina's website).</p> <p>We have designed a simple computational workflow to transform the raw <code>bcl</code> or <code>fastq</code> files from the sequencing of the barcoded library into table-like files (<code>csv</code>, or <code>tsv</code>) with contain the following information:</p> cell_bc x_pos y_pos CGCGAGGGGAAAATGGGGACTAGCG 6343 1016 GGTCCCGTCCAAGAAGTAAATCGAA 9272 1016 ... ... ... <p>Where <code>cell_bc</code> is the 25 nucleotide-long spatial barcode, and <code>x_pos</code>/<code>y_pos</code> are 2D spatial coordinates of a specific tile in the capture area (see below). </p> <p>Before diving into the code, let's clarify some of the terms that are specific to using Illumina flow cells as capture areas. We quote from  Illumina's documentation</p>"},{"location":"computational/preprocessing_capture_area/#flow-cell-related-terms","title":"Flow cell-related terms","text":"<p>Tiles</p> <p>\"Small imaging areas on the flow cell defined as the field of view by the  camera. The total number of tiles depends on the number of lanes, swaths, and surfaces that are imaged on  the flow cell, and how the cameras work together to collect the images.\"</p> <p>Lane</p> <p>\"A physical channel with dedicated input and output ports.\"</p> <p>Top/bottom</p> <p>\"The flow cell is imaged on two surfaces, the top and bottom. The top surface of 1 tile is imaged, then the bottom surface of the same tile is imaged before moving to the next tile.\"</p> <p>Swath</p> <p>\"A column of tiles in a lane.\"</p>"},{"location":"computational/preprocessing_capture_area/#generating-barcode-to-coordinate-map","title":"Generating barcode-to-coordinate map","text":"<p>For each flow cell, we generate plain text files with three columns: <code>cell_bc</code>, <code>x_pos</code>, and <code>y_pos</code>. These files are later used by <code>spacemake</code> to reconstruct the spatial coordinates from transcriptomic libraries.  This process is performed only once per barcoded flow cell.</p> <p>Software dependencies</p> <p>Running <code>openst flowcell_map</code> below requires installing either <code>bcl2fastq</code> or <code>bclconvert</code>. You can find instructions for <code>bcl2fastq</code>, and <code>bclconvert</code>.</p> <p>Then, make sure they are added to the <code>PATH</code> environment variable.</p> <p>For instance, in Linux:  <pre><code>export PATH=/path/to/bcl2fastq:$PATH\n# or\n# export PATH=/path/to/bclconvert:$PATH\n</code></pre></p> <p>Make sure you use a version of these softwares compatible with your sequencer.</p> <p>Once dependencies have been installed, create the barcode-to-coordinate map for all tiles:</p> <pre><code>openst flowcell_map \\\n    --bcl-in /path/to/fc/bcl \\\n    --tiles-out /path/to/fc_tiles \\\n    --crop-seq 5:30 \\  # for default Open-ST sequencing recipe\n    --rev-comp\n</code></pre> <p>Make sure to specify the arguments: - <code>--crop-seq</code>: Use a compatible Python slice (e.g., 5:30 will take 25 nucleotides, from the 6<sup>th</sup> to the 30<sup>th</sup> from the input reads) - <code>--rev-comp</code>: After cropping the sequences, will compute and store the reverse complement of the barcode sequences</p> <p>This command will create as many barcode-to-coordinate compressed text files as there are tiles in the flow cell under the folder <code>/path/to/fc_tiles</code></p>"},{"location":"computational/preprocessing_capture_area/#workflow-details","title":"Workflow Details","text":"<p>The <code>openst flowcell_map</code> command executes a multi-step workflow to process the barcode data:</p> <ol> <li>Tile Processing: Each of the 3,744 tiles (for the S4 flow cell) is processed individually using <code>bcl2fastq</code> (or <code>bclconvert</code>).</li> <li> <p>Barcode Preprocessing: The <code>barcode_preprocessing</code> function from our openst tools is applied to each tile. This step:</p> <ul> <li>Trims barcodes according to the specified <code>--crop-seq</code> parameter</li> <li>Computes the reverse complement of the barcodes (if <code>--rev-comp</code> is specified)</li> <li>Adds spatial coordinates (<code>x_pos</code> and <code>y_pos</code>) to each barcode</li> </ul> </li> <li> <p>Individual Tile Deduplication: Each processed tile file is deduplicated to remove duplicate barcodes within the same tile.</p> </li> <li>Cross-tile Merging and Deduplication: All deduplicated tile files are merged, and a second round of deduplication is performed to remove duplicate barcodes across different tiles.</li> <li>File Splitting: The merged and deduplicated data is split back into individual files, one for each original tile. This step facilitates faster processing with <code>spacemake</code> in subsequent analyses. The final tile files are compressed to save storage space.</li> </ol> <p>Coordinate system of tiles</p> <p>The spatial coordinates acquired with <code>bcl2fastq</code> (or <code>bclconvert</code>) are in a tile-specific coordinate system. For samples spanning multiple tiles, mapping to a global coordinate system becomes necessary. This global mapping is typically done using the <code>puck_collection</code> functionality from <code>spacemake</code>.</p>"},{"location":"computational/preprocessing_capture_area/#optional-retrieve-spatial-barcodes-coordinates-for-one-tile","title":"(Optional) Retrieve spatial barcodes coordinates for one tile","text":"<p>It is also possible to obtain per-tile barcodes and coordinates: </p> <pre><code>openst barcode_preprocessing \\\n    --fastq-in /path/to/tile.fastq \\\n    --tilecoords-out /path/to/fc_tiles \\\n    --out-prefix fc_1_ \\\n    --crop-seq 5:30 \\\n    --rev-comp \\\n    --single-tile\n</code></pre> <p>Warning</p> <p>These files do not undergo deduplication, therefore some barcodes might be repeated. Run <code>openst flowcell_map</code> to make sure there are no duplicated barcodes across the flow cell.</p> <p>Make sure to replace the placeholders. <code>/path/to/tile.fastq</code> to the <code>fastq</code> file of a specific tile; <code>/path/to/fc_tiles</code> where the table-like files will be written; <code>--out-prefix</code> (and <code>--out-suffix</code>) are prefixes and suffixes that are added to the tile file names; <code>--crop-seq 5:30</code> is a Python slice (e.g., 5:30 will take nucleotides 6<sup>th</sup> until 30<sup>th</sup> of the sequence in the <code>fastq</code> file); <code>--rev-comp</code> is provided whether the barcode sequences must be written into the <code>csv</code> as their reverse-complementary, after cropping; <code>--single-tile</code> argument is provided when the <code>fastq</code> file only contains data for a single tile (our recommendation).</p>"},{"location":"computational/preprocessing_capture_area/#expected-output","title":"Expected output","text":"<p>After running all the steps of this section, you will have a folder <code>/path/to/fc_tiles</code> with <code>*.txt.gz</code> files containing the spatial coordinates of flow cell tiles. You only need to generate this once per flow cell.</p>"},{"location":"computational/preprocessing_openst_library/","title":"Preprocessing transcriptomic library","text":"<p>After sequencing the transcriptomic sequences of Open-ST library,  you will get basecall files in <code>bcl</code> format, or raw reads in <code>fastq</code> format  (see sequence file formats from Illumina's website).</p> <p>For the Open-ST workflow, we leverage <code>spacemake</code>, an an automated pipeline designed for the preprocessing, alignment, and quantification of single-cell and spatial transcriptomics data.</p>"},{"location":"computational/preprocessing_openst_library/#configuring-spacemake","title":"Configuring <code>spacemake</code>","text":"<p>We refer to the official documentation for a complete tutorial on how to  install and initialize spacemake. </p> <p>Once installed, initialized and species data have been added, an Open-ST sample can be added:</p> <pre><code>spacemake projects add_sample \\\n   --project_id &lt;project_id&gt; \\\n   --sample_id &lt;sample_id&gt; \\\n   --R1 &lt;path_to_R1.fastq.gz&gt; \\ # single R1 or several R1 files\n   --R2 &lt;path_to_R2.fastq.gz&gt; \\ # single R2 or several R2 files\n   --species &lt;species&gt; \\\n   --puck openst \\\n   --puck_barcode_file &lt;path_to_puck_barcode_file.tsv.gz&gt; \\\n   --run_mode openst \\\n   --barcode_flavor openst\n</code></pre> <p>The above will add a new Open-ST project with <code>barcode_flavor</code>, <code>run_mode</code>, <code>puck</code> all set to <code>openst</code>.</p> How to populate <code>--puck_barcode_file</code> <p>With Open-ST data, each sample covers a piece of capture area, which contains at least one tile (puck).</p> <p>Thus, we need to provide <code>--puck_barcode_file</code> (each tile in a sample has different barcodes, unlike for visium samples). This file should be a comma or tab separated, containing column names as first row. Acceptable column names are:</p> <ul> <li><code>cell_bc</code>, <code>barcodes</code> or <code>barcode</code> for cell-barcode</li> <li><code>xcoord</code> or <code>x_pos</code> for x-positions</li> <li><code>ycoord</code> or <code>y_pos</code> for y-positions</li> </ul> <p>These are generated by the <code>openst</code> package as previously described.</p> <p>All <code>puck_barcode_files</code> generated in the  previous step at the folder <code>/path/to/fc_tiles</code>  need to be specified after <code>--puck_barcode_file</code>, e.g., with the wildcards <code>/path/to/fc_tiles/*.txt.gz</code>.</p> <p>To generate output files and reports only for the relevant tiles per sample, you can configure the variable <code>spatial_barcode_min_matches</code> under <code>run_mode</code> (see spacemake documentation). This represents the minimum proportion of spatial barcodes that a tile must have in common  with the sample transcriptomic data to be further included during quantification and downstream analysis.</p> <p>Tip</p> <p>If some tiles are wrongly missing (present), this might be because the threshold was too high (low).  You can update the sample to add missing tiles (see spacemake documentation). Then, rerun spacemake by configuring <code>spatial_barcode_min_matches</code> to zero.</p>"},{"location":"computational/preprocessing_openst_library/#running-spacemake","title":"Running <code>spacemake</code>","text":"<p>After a sample is added spacemake can be run with:</p> <pre><code>spacemake run --cores &lt;n_cores&gt; --keep-going\n</code></pre> <p>The <code>--keep-going</code> flag is optional, however it will ensure that spacemake runs all the jobs it can, even if one job fails (this logic is directly taken from snakemake).</p>"},{"location":"computational/preprocessing_openst_library/#expected-output","title":"Expected output","text":"<p>After running all the steps of this section, <code>spacemake</code> generates the following folder structure (e.g., for a single sample): <pre><code>spacemake_folder\n`-- projects\n    `-- &lt;project_id&gt;\n        |-- processed_data\n        |   `-- &lt;sample_id&gt;\n        |       `-- illumina\n        |           `-- complete_data\n        |               |-- dge # folder, spatial gene expression as h5ad files \n        |               |-- qc_sheets # folder, sequencing QC as HTML\n        |               |-- automated_analysis # folder, automated analysis results as HTML\n        |               `-- ... # intermediate output files and folders\n        `-- raw_data # folder, contains R1 and R2 reads (fastq)\n</code></pre></p> <p>Importantly for the <code>openst</code> pipeline are the <code>h5ad</code> file(s) per sample (under the <code>dge</code> folder), which contain the gene expression and spatial coordinates of each barcoded spot. </p> <p>In the following sections, you will learn how to merge and align these with imaging data, to later aggregate transcriptomic information into single cells, rather than using a more arbitrary regular binning of  spatial data into squares or hexagons (part of the output from <code>spacemake</code> for QC purposes).</p>"},{"location":"computational/threed_reconstruction/","title":"3D reconstruction from serial sections of spatial transcriptomics and H&amp;E images","text":"<p>In this section, we will guide you through the process of creating a 3D reconstruction from serial sections of spatial transcriptomics (ST) and H&amp;E images using the Spatial Transcriptomics ImgLib2/Imaging Project (STIM, v0.2.0). This reconstruction allows you to gain a comprehensive understanding of your biological samples in three dimensions.</p>"},{"location":"computational/threed_reconstruction/#creation-of-csv-files","title":"Creation of csv files","text":"<p>Use the provided script</p> <pre><code>openst to_3d_registration --args --metadata=&lt;where_to_write_metadata&gt;\n</code></pre>"},{"location":"computational/threed_reconstruction/#conversion-to-n5-format","title":"Conversion to n5 format","text":"<p>Convert the coordinate and gene expression information of these datasets into the n5 format, which is optimized for efficient image processing, using the st-resave function. <pre><code>STIMBINS=\"/home/dleonpe/data/bin\"\nSTIMINFILES=\"/data/rajewsky/home/dleonpe/projects/openst_paper/data/2_downstream/fc_sts_63/aligned_sections/1_input\"\nSTIMOUTFILES=\"/data/rajewsky/home/dleonpe/projects/openst_paper/data/2_downstream/fc_sts_63/aligned_sections/2_stim_dataset\"\nFNAME=\"stitched_spots_merged_aligned_10px_GAN_segmented.h5ad.\"\n\n$STIMBINS/st-resave \\\n    -i \"$STIMINFILES/fc_sts_63_2_${FNAME}locations.csv,$STIMINFILES/fc_sts_63_2_${FNAME}genes.csv,fc_sts_63_02\" \\\n    -i \"$STIMINFILES/fc_sts_63_3_${FNAME}locations.csv,$STIMINFILES/fc_sts_63_3_${FNAME}genes.csv,fc_sts_63_03\" \\\n    -o \"$STIMOUTFILES/fc_sts_63.n5\" \\\n    --normalize\n</code></pre></p>"},{"location":"computational/threed_reconstruction/#pairwise-alignment","title":"Pairwise alignment","text":"<p>Utilize the st-align-pairs function to perform pairwise alignment of three sections below and above each section (r=3). This function creates image channels of gene expression for prespecified genes, aggregated per cell as a Gauss rendering around centroids, parametrized with a smoothness factor.</p> <pre><code>STIMBINS=\"/home/dleonpe/data/bin\"\nSTIMOUTFILES=\"/data/rajewsky/home/dleonpe/projects/openst_paper/data/2_downstream/fc_sts_63/aligned_sections/2_stim_dataset\"\n\n# 2. Run pairwise alignment\n$STIMBINS/st-align-pairs \\\n     -i \"$STIMOUTFILES/fc_sts_63.n5\" \\\n     --scale 0.03 \\\n     -r 3 \\\n     --hidePairwiseRendering \\\n     --overwrite \\\n     -sf 4.0 \\\n     --minNumInliers 15 \\\n     --numGenes 0 \\\n     -g 'KRT6A,KRT6B,S100A2,LYZ,CD74,IGKC,IGHG1,IGHA1,JCHAIN,CD74,AMTN'\n     #--numGenes 20 \\\n</code></pre>"},{"location":"computational/threed_reconstruction/#feature-filtering-and-global-alignment","title":"Feature Filtering and Global Alignment","text":"<p>Filter the resulting set of feature matches between pairs of sections using an affine model. Configure the st-align-pairs function with appropriate parameters, such as --minNumInliers 15, --scale 0.03, and -sf 4.0 (smoothness factor). <pre><code>STIMBINS=\"/home/dleonpe/data/bin\"\nSTIMOUTFILES=\"/data/rajewsky/home/dleonpe/projects/openst_paper/data/2_downstream/fc_sts_63/aligned_sections/2_stim_dataset\"\n\n$STIMBINS/st-align-global \\\n     -i \"$STIMOUTFILES/fc_sts_63.n5\" \\\n     --skipICP \\\n     -g 'KRT6A,KRT6B,S100A2,LYZ,CD74,IGHG1,IGHA1,JCHAIN,CD74,AMTN'\n</code></pre></p>"},{"location":"computational/threed_reconstruction/#conversion-to-h5ad-format","title":"Conversion to h5ad Format","text":"<p>Convert the n5 container back to the h5ad format for subsequent downstream analyses. This will also transfer the transformation models from the ST alignment onto the preprocessed and background-removed H&amp;E images. This script will output the aligned spatial coordinates and an image volume that can be used for subsequent 3D visualization, of spatial transcriptomics and H&amp;E staining in a common coordinate system. <pre><code>openst from_3d_registration --args --metadata=&lt;where_to_write_metadata&gt;\n</code></pre></p> <p>You can quickly generate a HTML report to visualize the alignment quality. This will provide, for instance, a volumetric rendering on your browser using the channels (genes) selected for registration. This will also visualize the sections individually, to assess the deformations per section after registration, as well as the deformation fields.</p> <pre><code>openst report --metadata=&lt;where_to_write_metadata&gt; --output=&lt;path_to_html_file&gt;\n</code></pre> <p>With these steps completed, you will have successfully reconstructed a 3D representation of your biological samples, integrating spatial transcriptomics data and H&amp;E images. This 3D reconstruction provides valuable insights into the spatial distribution of gene expression within your samples and enhances your understanding of complex biological structures.</p>"},{"location":"computational/threed_reconstruction/#3d-visualization-with-paraview","title":"3D visualization with ParaView","text":"<p>(explain)</p>"},{"location":"examples/datasets/","title":"Datasets","text":"<p>Here we provide a single table with some links, size and md5 checksums for the files provided in the following tutorials.</p> <p>Tip</p> <p>All raw reads for the datasets showcased in our paper are available at SRA, and all processed objects (H&amp;E images and spatial transcriptomes) are available at GEO</p> <p>Tip</p> <p>When downloading any of the files below, using Linux or macOS, we recommend <code>wget</code>.</p>"},{"location":"examples/datasets/#adult-mouse-hippocampus","title":"Adult mouse hippocampus","text":"File Link md5 checksum adult_hippocampus_tiles.tar.xz http 3788d6774212d8eb50ffb17fc970c1c3 adult_mouse_hippocampus.h5ad.tar.gz http 833bd94d8901b6605fd41c22e5755e1c adult_mouse_hippocampus_by_cell.h5ad.tar.gz http c837f3184d25fb4842a0e27bde1b3941 adult_mouse_hippocampus_R1_001.fastq.gz http cff74ca79bfa645de31cee80f035b6fe adult_mouse_hippocampus_R2_001.fastq.gz http 4f3af67c09967ca6bdd9575a02692a4f adult_mouse_hippocampus.tif http d23dba7f2eeb88c3de9fa869099b30dd"},{"location":"examples/datasets/#e13-mouse-head","title":"E13 mouse head","text":"File Link md5 checksum e13_mouse_head_tiles.tar.xz http a7f63b5049a8e06d9c3a37cab7af8205 e13_mouse_head.h5ad.tar.gz http c727ec6d7b34bffd79919570ae5b4b6d e13_mouse_head_R1_001.fastq.gz http 92f291e2033bf71096836a239a49fc1e e13_mouse_head_R2_001.fastq.gz http 841e5a8fe667f247e6dc4bd9641a3cc8 e13_mouse_head_reseq_R1_001.fastq.gz http 43c8a107652022f6f675bbd761dc330d e13_mouse_head_reseq_R2_001.fastq.gz http a6a7c0cb3c6626977444b43a9ba07450 e13_mouse_head.tif http c7703951d2602d487d0336c7c50f49c6"},{"location":"examples/datasets/#barcode-spatial-coordinates-and-coordinate-systems","title":"Barcode spatial coordinates and coordinate systems","text":"File Link md5 checksum fc_1_coordinate_system.csv http 83016d6d9179b68dbfe07d1da01aa0c0 fc_2_coordinate_system.csv http 6da374f1d4b07b2d3c8c424e76fa8567 fc_1_L3.fastq.gz http 7ee4cc818708caa87401744ac9366732 fc_2_L3.fastq.gz http 67e2d95e9b17bc8ebdf9f315f9a09952"},{"location":"examples/datasets/#genomes-and-annotations","title":"Genomes and annotations","text":"File Link md5 checksum GRCm39vM30.genome.fa http f7e956ab58169c9b457c93bc7ecca0a2 gencodevM30.annotation.gtf http de5e3b939daf633970582756f90c01df phiX.fa http 69a6c72e164d1a57c0f8cf375a246b0a mouse.rRNA.fa http cbf1d516d570cf085c9d5a61ac1b97c5"},{"location":"examples/getting_started/","title":"Examples","text":"<p>Here you will find datasets generated in the Rajewsky lab @ MDC Berlin leveraging the Open-ST workflow (experimental and computational). </p>"},{"location":"examples/getting_started/#datasets","title":"Datasets","text":"<p>We provide raw data, instructions on how to reproduce the preprocessing pipeline, the corresponding preprocessed data (for comparison), and notebooks for some exploratory visualization and downstream analysis. We publicly provide mouse datasets, showcased in the paper.</p> <ul> <li> Adult mouse hippocampus</li> <li> E13 mouse head</li> <li> Human HNSCC, healthy and metastatic lymph node</li> </ul>"},{"location":"examples/adult_mouse/generate_expression_matrix/","title":"Segmentation and single-cell quantification","text":"<p>Once the ST and imaging modalities have been aligned, you can segment the images into single cells/nuclei,  and then aggregate the spot locations into individual cells for subsequent analysis.</p>"},{"location":"examples/adult_mouse/generate_expression_matrix/#segmentation-of-staining-image","title":"Segmentation of staining image","text":"<p>First, segment the imaging data into single nuclei. For this dataset, the default <code>HE_cellpose_rajewsky</code> works really well.</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_adult_mouse \\\n    segment \\\n    --image-in 'uns/spatial_pairwise_aligned/staining_image_transformed' \\\n    --mask-out 'uns/spatial/staining_image_mask' \\\n    --model models/HE_cellpose_rajewsky \\\n    --dilate-px 0 \\\n    --device cuda\n</code></pre>"},{"location":"examples/adult_mouse/generate_expression_matrix/#assigning-transcripts-to-segmented-cells","title":"Assigning transcripts to segmented cells","text":"<p>Now, aggregate the initial barcoded spots-by-gene matrix into a cells(nuclei)-by-genes matrix, by leveraging the segmentation mask.</p> <p>This step allows you to aggregate capture spots by segmented cells (nuclei):</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_adult_mouse \\\n    transcript_assign \\\n    --spatial-key obsm/spatial_manual_fine\n</code></pre>"},{"location":"examples/adult_mouse/generate_expression_matrix/#expected-output","title":"Expected output","text":"<p>That's it! After running the steps above, you will have that single file which contains the transcriptomic information per segmented cell (nucleus).</p> <p>Warning</p> <p>Do not expect the files to be exactly the same to the ones we generated, as there are several steps on the pipeline that may not be deterministic (e.g., alignment, segmentation).</p> <p>Now, the following section provides some examples of exploratory data analysis.</p>"},{"location":"examples/adult_mouse/introduction/","title":"Introduction","text":"<p>In our paper, we used an adult mouse hippocampus sample to carefully benchmark the precision, sensitivity, and spatial resolution of RNA capture due to the high availability of published gene expression data (RNA-seq, in-situ hybridization, ST, etc.) and the possibility to maintain RNA quality by controlling sample handling and timing. </p> <p>In the following sections, we explore how to reproduce the preprocessing steps for this data, and provide an example notebook for exploratory data analysis of the data using standard single cell tools.</p>"},{"location":"examples/adult_mouse/pairwise_alignment/","title":"Pairwise alignment","text":"<p>In the previous step, the transcriptomic reads were processed and mapped in tissue space with <code>spacemake</code>. Now, we perform a pairwise alignment between the imaging and spatial transcriptomics modality, such that we can later aggregate transcripts into individual cells delimited by the segmentation mask.</p> <p>We will illustrate how to do this in a semiautomatic manner: that is, running the coarse alignment in an automatic fashion, and the fine alignment (to fiducial marks) via GUI, in a manual manner. Although we provide models for fiducial feature detection, the accuracy might be affected by the type of microscope, imaging strategy, tissue type and width... Thus, manual fine alignment is a good option. This can be done very quickly thanks to the GUI specifically designed for this task (~5 minutes per sample of 12 tiles).</p>"},{"location":"examples/adult_mouse/pairwise_alignment/#download-and-copy-image-data","title":"Download and copy image data","text":"<p>For this dataset, we archived the stitched tile-scan image.  This single image was generated from multiple, independently imaged tiles, by leveraging <code>openst image_stitch</code>. So,  you don't need to use this command, since we already provide the stitched image. Anyway, let us know if you want access to this tile images, in case you want to try.</p> <p>As well, the imaging from this dataset did not require any further postprocessing prior to segmentation, as visual inspection of the images did not reveal any strong illumination or focus biases. </p> <p></p> <p>You can download the image data from the link above</p> <pre><code>wget \"https://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/adult_mouse_hippocampus.tif\"\n</code></pre> <p>and then copy it into relevant path, for example:</p> <pre><code>mkdir spacemake_folder/projects/openst_demo/processed_data/openst_demo_adult_mouse/imaging\ncp adult_mouse_hippocampus.tif \\\n    spacemake_folder/projects/openst_demo/processed_data/openst_demo_adult_mouse/imaging/Image_Stitched_Composite.tif\n</code></pre> <p>the final folder structure should look like:</p> <pre><code>spacemake_folder\n`-- projects\n    `-- openst_demo\n        `-- processed_data\n            `-- openst_demo_adult_mouse\n                `-- imaging\n                    `-- Image_Stitched_Composite.tif\n</code></pre>"},{"location":"examples/adult_mouse/pairwise_alignment/#merging-data-modalities","title":"Merging data modalities","text":"<p>From the relevant <code>spacemake</code> main folder, merge both transcriptomics and imaging modalities</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_adult_mouse \\\n    merge_modalities\n</code></pre>"},{"location":"examples/adult_mouse/pairwise_alignment/#coarse-pairwise-alignment-auto","title":"Coarse pairwise alignment (auto)","text":"<p>Once the two modalities have been merged, you can run automatic alignment. Here we only run coarse (<code>--only-coarse</code>), so we can showcase how to do manual refinement with the GUI.</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_adult_mouse \\\n    pairwise_aligner \\\n    --only-coarse \\\n    --device cuda\n</code></pre> <p>Note</p> <p>For this image data, and the spatial coordinates after alignment, the conversion factor to physical distance is 1 pixel = 0.345 \u00b5m.</p>"},{"location":"examples/adult_mouse/pairwise_alignment/#fine-pairwise-alignment-manual","title":"Fine pairwise alignment (manual)","text":"<p>Now you can assess the pairwise alignment visually, and refine it using the provided GUI tool. </p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_adult_mouse \\\n    manual_pairwise_aligner \\\n    --spatial-key obsm/spatial_pairwise_aligned_coarse \\\n    --image-key uns/spatial_pairwise_aligned/staining_image_transformed\n</code></pre> <p>Then, follow the following steps:</p> <ol> <li>Select the all_tiles_coarse layer from the Layer selector, and click on Render. You will see the staining image on the upper left,    the transcriptomic image on the top right, and the merge on the bottom left. These two modalities should roughly match. If not, you would need to    run the coarse (low-res) alignment in manual mode, too.</li> <li>If the coarse alignment looks good, select layer '0' and click Render.</li> <li>Select pairs of corresponding fiducial markers (at least 3) on both modalities by double clicking on the left image, first, and on the right image, second. You can drag the points to new locations, zoom into the images with the mouse wheel, pan the image by holding the mouse right cursor and moving, and remove the points by pressing backspace on your keyboard. You can preview how the alignment will look like after transformation by pressing Preview alignment.</li> <li>Repeat from 2, but selecting a new layer every time ('1', '2', ...).</li> <li>Once you've finished with all tiles, go under Keypoint properties and click Save keypoints as <code>keypoints.json</code>.</li> </ol> <p>With this, you have created a <code>keypoints.json</code> file containing pairs of corresponding points between the spatial trancriptome and image modalities. </p>"},{"location":"examples/adult_mouse/pairwise_alignment/#apply-keypoint-transformation","title":"Apply keypoint transformation","text":"<p>Then, compute apply the rigid transformations to the coarsely aligned spatial coordinates:</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_adult_mouse \\\n    apply_transform \\\n    --keypoints-in keypoints.json \\\n    --spatial-key-out obsm/spatial_manual_fine \\\n    --per-tile\n</code></pre> <p>The <code>--per-tile</code> is important to perform this operation per tile. Otherwise, <code>apply_transform</code> will assume that the transform needs to be done for all coordinates, and will expect that you have selected corresponding keypoints for the layer all_tiles_coarse.</p> <p>That's it! Now you're ready to go to the next step.</p>"},{"location":"examples/adult_mouse/preprocessing_sequencing/","title":"Preprocessing transcriptomic library","text":"<p>After sequencing, we proceed with the preprocessing of the data, to go from raw reads to transcriptomic information mapped to the mouse genome, in space.</p>"},{"location":"examples/adult_mouse/preprocessing_sequencing/#demultiplexing","title":"Demultiplexing","text":"<p>We got basecall files in <code>bcl</code> format from our sequencing facility.</p> <p>We used <code>bcl2fastq</code> for demultiplexing, using this sample sheet. We used the conda environment where we installed <code>spacemake</code> (see instructions on how to install spacemake), and ran the following commands:</p> <pre><code>(base) user@computer:~$ bcl2fastq \\\n    --no-lane-splitting \\\n    --runfolder-dir /openst/data/0_basecalls/230616_VH01346_22_AAC2LVVHV \\\n    -o /openst/data/1_spacemake_mouse/demultiplexed_data \\\n    --sample-sheet /openst/data/0_sample_sheets/230616_NR_FC_ST_72_76_AT_01.csv\n</code></pre> <p>We obtained <code>fastq</code> files that will be used for the rest of the pipeline, for Read 1 and Read 2. Once you download these files, you can move them anywhere in your filesystem. We assume that you have opened a terminal, and you have browsed to your home directory. From there, create a folder <code>openst_adult_demo</code>; browse inside, and create another folder <code>data</code>. Then, copy the folder with the <code>fastq</code> files in here. You should have a structure like:</p> <pre><code>/home/user\n|-- openst_adult_demo\n|   `-- data\n|       `-- fastq\n</code></pre>"},{"location":"examples/adult_mouse/preprocessing_sequencing/#transcriptomic-spatial-mapping-with-spacemake","title":"Transcriptomic &amp; spatial mapping with <code>spacemake</code>","text":"<p>First of all, intialize the conda environment for <code>spacemake</code> <pre><code>(base) user@computer:~$ conda activate spacemake\n(spacemake) user@computer:~$\n</code></pre></p>"},{"location":"examples/adult_mouse/preprocessing_sequencing/#initialize","title":"Initialize","text":"<p>Create two folders inside your <code>openst_adult_demo</code> folder, called <code>spacemake</code> and <code>bins</code>, so you will have:</p> <pre><code>/home/user\n|-- openst_adult_demo\n|   |-- data\n|   |   `-- fastq\n|   |-- spacemake\n|   `-- bins\n</code></pre> <p>Download the DropSeq tools, decompress it, and put it inside the <code>bins</code> subdirectory.</p> <p>Then, following the spacemake Quick start guide, browse to the <code>spacemake</code> directory you just created in the <code>openst_adult_demo</code> folder, and run the initialization:</p> <pre><code>(spacemake) user@computer:~$ cd /home/user/openst_adult_demo/spacemake\n(spacemake) user@computer:/home/user/openst_adult_demo/spacemake$ spacemake init\n    --dropseq_tools /home/user/bins/Drop-seq_tools-2.5.1\n</code></pre>"},{"location":"examples/adult_mouse/preprocessing_sequencing/#configure","title":"Configure","text":"<p>As <code>spacemake</code> comes with no default value for species, before anything can be done, a new species has to be added. In this case, we add mouse; you will need to download the correct <code>fa</code> and <code>gtf</code> files. For instance, you can download the mouse genome from gencode, as well as the annotation.</p> <p>Then, you need to run the following commands (remember, in the same <code>spacemake</code> folder as before, with the <code>spacemake</code> conda environment; we are going to omit <code>(spacemake) user@computer:/home/user/openst_adult_demo/spacemake$</code> for brevity).</p> <pre><code>spacemake config add_species \\\n   --name mouse \\\n   --reference genome \\\n   --sequence GRCm39vM30.genome.fa \\\n   --annotation gencodevM30.annotation.gtf\n\nspacemake config add_species \\\n   --name mouse \\\n   --reference rRNA \\\n   --sequence mouse.rRNA.fa\n\nspacemake config add_species \\\n   --name mouse \\\n   --reference phiX \\\n   --sequence phiX.fa\n</code></pre> <p>Note</p> <p>The <code>.fa</code> and <code>.gtf</code> files for mouse are available for http download under the example datasets page. For instance, you can run:</p> <pre><code># for the mouse genome sequence\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/genomes/GRCm39vM30.genome.fa\"\n# etc...\n</code></pre>"},{"location":"examples/adult_mouse/preprocessing_sequencing/#add-sample","title":"Add sample","text":"<p>Now you need to add the sample data and metadata to <code>spacemake</code>. For this, you will also need the puck (tile) barcode files, which can be generated with the <code>openst</code> package.</p> <p>For simplicity, we provide the tile barcode files that are related to this sample, as well as the coordinate system  for the Illumina flow cell that was used to generate the capture area of this experiment.</p> <p>When downloading the tile barcode files, create a folder under <code>openst_adult_demo/data</code> called <code>tiles</code>. Move the files of the tile barcode files into this folder. Also, move the coordinate file to the <code>puck_data</code> folder in the <code>spacemake</code> directory.</p> <p>Remember! You need to be in the <code>/home/user/openst_adult_demo/spacemake</code> directory (or similar, depending on what you created); then run the following commands:</p> <pre><code># downloading R1 and R2 sequences\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/adult_mouse_hippocampus_R1_001.fastq.gz\"\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/adult_mouse_hippocampus_R2_001.fastq.gz\"\n\n# downloading the spatial barcode sequences\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/adult_hippocampus_tiles.tar.xz\"\ntar -xvf adult_hippocampus_tiles.tar.xz\n\nspacemake projects add_sample \\\n    --project_id openst_demo \\\n    --sample_id openst_demo_adult_mouse \\\n    --R1 adult_mouse_hippocampus_R1_001.fastq.gz \\\n    --R2 adult_mouse_hippocampus_R2_001.fastq.gz \\\n    --species mouse \\\n    --puck openst \\\n    --run_mode openst \\\n    --barcode_flavor openst \\\n    --puck_barcode_file adult_hippocampus_tiles/*.txt.gz \\\n    --map_strategy \"bowtie2:phiX-&gt;bowtie2:rRNA-&gt;STAR:genome:final\"\n</code></pre> <p>You can specify the coordinate system by modifying the <code>openst</code> run mode in the <code>config.yaml</code> file that is created after you run the <code>spacemake init</code> command (see above). Modify the following lines from this:</p> <pre><code>openst:\n    coordinate_system: puck_data/openst_coordinates.csv\n    spot_diameter_um: 0.6\n    width_um: 1200\n</code></pre> <p>into this:</p> <pre><code>openst:\n    coordinate_system: puck_data/fc_2_coordinate_system.csv\n    spot_diameter_um: 0.6\n    width_um: 1200\n</code></pre> <p>You can download the coordinate system file from the Open-ST website, for example:</p> <pre><code># download the coordinate system\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/fc_2_coordinate_system.csv\"\ncp fc_2_coordinate_system.csv puck_data/.\n</code></pre>"},{"location":"examples/adult_mouse/preprocessing_sequencing/#run","title":"Run","text":"<p>That's all you need to configure! Now, you can run spacemake with the following:</p> <pre><code>spacemake run --cores 32\n</code></pre> <p>You can modify the number of <code>--cores</code> depending on your local machine; also, you can specify additional arguments to <code>spacemake run</code> - refer to the official documentation.</p>"},{"location":"examples/adult_mouse/preprocessing_sequencing/#expected-output","title":"Expected output","text":"<p>Once <code>spacemake</code> finishes, you will see that several folders and files have been created under <code>projects</code> (inside the <code>spacemake</code> directory). For example, you can check the QC reports in your web browser by opening the file at <code>projects/openst_demo/processed_data/openst_demo_adult_mouse/illumina/complete_data/qc_sheets/qc_sheet_openst_demo_adult_mouse_fc_1_puck_collection.html</code>, giving you a first impression of what's the quality of spatial mapping, amount of transcripts and genes per barcoded spot, and others.</p> <p>Importantly, you will find files in the directory <code>projects/openst_demo/processed_data/openst_demo_adult_mouse/illumina/complete_data/dge</code> with the name <code>dge.all.polyA_adapter_trimmed.mm_included.spatial_beads_*.h5ad</code> (where <code>*</code> is a wildcard). These files, and not the ones containing  the words <code>mesh</code>, <code>hexagon</code> or <code>circle</code> are the ones that will be used later to perform the pairwise alignment with imaging data, and to later reconstruct the cell-by-gene matrix.</p> <p>If you specified options for meshing in the <code>run_mode</code>, there will be a file containing keywords <code>puck_collection</code> and <code>mesh</code>, <code>hexagon</code> or <code>circle</code>. This contains approximate cell-by-gene information, as the transcripts are aggregated by a regular lattice and not by the true spatial arrangement of cells. This might be already enough for some analyses. </p> <p>Anyway... keep going with the tutorial if you want to unleash the full potential of Open-ST.</p>"},{"location":"examples/e13_mouse/generate_expression_matrix/","title":"Segmentation and single-cell quantification","text":"<p>Once the ST and imaging modalities have been aligned, you can segment the images into single cells/nuclei,  and then aggregate the spot locations into individual cells for subsequent analysis.</p>"},{"location":"examples/e13_mouse/generate_expression_matrix/#segmentation-of-staining-image","title":"Segmentation of staining image","text":"<p>First, segment the imaging data into single nuclei. For this dataset, the default <code>HE_cellpose_rajewsky</code> works really well.</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_e13_mouse_head \\\n    segment \\\n    --image-in 'uns/spatial_pairwise_aligned/staining_image_transformed' \\\n    --mask-out 'uns/spatial/staining_image_mask' \\\n    --model models/HE_cellpose_rajewsky \\\n    --dilate-px 0 \\\n    --device cuda\n</code></pre>"},{"location":"examples/e13_mouse/generate_expression_matrix/#assigning-transcripts-to-segmented-cells","title":"Assigning transcripts to segmented cells","text":"<p>Now, aggregate the initial barcoded spots-by-gene matrix into a cells(nuclei)-by-genes matrix, by leveraging the segmentation mask.</p> <p>This step allows you to aggregate capture spots by segmented cells (nuclei):</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_e13_mouse_head \\\n    transcript_assign \\\n    --spatial-key obsm/spatial_manual_fine\n</code></pre>"},{"location":"examples/e13_mouse/generate_expression_matrix/#expected-output","title":"Expected output","text":"<p>That's it! After running the steps above, you will have that single file which contains the transcriptomic information per segmented cell (nucleus).</p> <p>Warning</p> <p>Do not expect the files to be exactly the same to the ones we generated, as there are several steps on the pipeline that may not be deterministic (e.g., alignment, segmentation).</p> <p>Now, the following section provides some examples of exploratory data analysis.</p>"},{"location":"examples/e13_mouse/introduction/","title":"Introduction","text":"<p>In our paper, we used an E13 mouse head sample to benchmark the precision, sensitivity, and spatial resolution of RNA capture due to the high availability of published gene expression data (RNA-seq, in-situ hybridization, ST, etc.) and the possibility to maintain RNA quality by controlling sample handling and timing. </p> <p>In the following sections, we explore how to reproduce the preprocessing steps for this data, and provide an example notebook for exploratory data analysis of the data using standard single cell tools.</p>"},{"location":"examples/e13_mouse/pairwise_alignment/","title":"Pairwise alignment","text":"<p>In the previous step, the transcriptomic reads were processed and mapped in tissue space with <code>spacemake</code>. Now, we perform a pairwise alignment between the imaging and spatial transcriptomics modality, such that we can later aggregate transcripts into individual cells delimited by the segmentation mask.</p> <p>We will illustrate how to do this in a semiautomatic manner: that is, running the coarse alignment in an automatic fashion, and the fine alignment (to fiducial marks) via GUI, in a manual manner. Although we provide models for fiducial feature detection, the accuracy might be affected by the type of microscope, imaging strategy, tissue type and width... Thus, manual fine alignment is a good option. This can be done very quickly thanks to the GUI specifically designed for this task (~5 minutes per sample of 12 tiles).</p>"},{"location":"examples/e13_mouse/pairwise_alignment/#download-and-copy-image-data","title":"Download and copy image data","text":"<p>For this dataset, we archived the stitched tile-scan image.  This single image was generated from multiple, independently imaged tiles, by leveraging <code>openst image_stitch</code>. So,  you don't need to use this command, since we already provide the stitched image. Anyway, let us know if you want access to this tile images, in case you want to try.</p> <p>You can download the iamge data from the link above</p> <pre><code>wget \"https://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/e13_mouse_head.tif\"\n</code></pre> <p>and then copy it into relevant path, for example:</p> <pre><code>mkdir spacemake_folder/projects/openst_demo/processed_data/openst_demo_e13_mouse_head/imaging\ncp e13_mouse_head.tif \\\n    spacemake_folder/projects/openst_demo/processed_data/openst_demo_e13_mouse_head/imaging/Image_Stitched_Composite.tif\n</code></pre> <p>the final folder structure should look like:</p> <pre><code>spacemake_folder\n`-- projects\n    `-- openst_demo\n        `-- processed_data\n            `-- openst_demo_e13_mouse_head\n                `-- imaging\n                    `-- Image_Stitched_Composite.tif\n</code></pre>"},{"location":"examples/e13_mouse/pairwise_alignment/#merging-data-modalities","title":"Merging data modalities","text":"<p>From the relevant <code>spacemake</code> main folder, merge both transcriptomics and imaging modalities</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_e13_mouse_head \\\n    merge_modalities\n</code></pre>"},{"location":"examples/e13_mouse/pairwise_alignment/#coarse-pairwise-alignment-auto","title":"Coarse pairwise alignment (auto)","text":"<p>Once the two modalities have been merged, you can run automatic alignment. Here we only run coarse (<code>--only-coarse</code>), so we can showcase how to do manual refinement with the GUI.</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_e13_mouse_head \\\n    pairwise_aligner \\\n    --only-coarse \\\n    --device cuda\n</code></pre> <p>Note</p> <p>For this image data, and the spatial coordinates after alignment, the conversion factor to physical distance is 1 pixel = 0.345 \u00b5m.</p>"},{"location":"examples/e13_mouse/pairwise_alignment/#fine-pairwise-alignment-manual","title":"Fine pairwise alignment (manual)","text":"<p>Now you can assess the pairwise alignment visually, and refine it using the provided GUI tool. </p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_e13_mouse_head \\\n    manual_pairwise_aligner \\\n    --spatial-key obsm/spatial_pairwise_aligned_coarse \\\n    --image-key uns/spatial_pairwise_aligned/staining_image_transformed\n</code></pre> <p>Then, follow the following steps:</p> <ol> <li>Select the all_tiles_coarse layer from the Layer selector, and click on Render. You will see the staining image on the upper left,    the transcriptomic image on the top right, and the merge on the bottom left. These two modalities should roughly match. If not, you would need to    run the coarse (low-res) alignment in manual mode, too.</li> <li>If the coarse alignment looks good, select layer '0' and click Render.</li> <li>Select pairs of corresponding fiducial markers (at least 3) on both modalities by double clicking on the left image, first, and on the right image, second. You can drag the points to new locations, zoom into the images with the mouse wheel, pan the image by holding the mouse right cursor and moving, and remove the points by pressing backspace on your keyboard. You can preview how the alignment will look like after transformation by pressing Preview alignment.</li> <li>Repeat from 2, but selecting a new layer every time ('1', '2', ...).</li> <li>Once you've finished with all tiles, go under Keypoint properties and click Save keypoints as <code>keypoints.json</code>.</li> </ol> <p>With this, you have created a <code>keypoints.json</code> file containing pairs of corresponding points between the spatial trancriptome and image modalities. </p>"},{"location":"examples/e13_mouse/pairwise_alignment/#apply-keypoint-transformation","title":"Apply keypoint transformation","text":"<p>Then, compute apply the rigid transformations to the coarsely aligned spatial coordinates:</p> <pre><code>openst from_spacemake \\\n    --project-id openst_demo \\\n    --sample-id openst_demo_e13_mouse_head \\\n    apply_transform \\\n    --keypoints-in keypoints.json \\\n    --spatial-key-out obsm/spatial_manual_fine \\\n    --per-tile\n</code></pre> <p>The <code>--per-tile</code> is important to perform this operation per tile. Otherwise, <code>apply_transform</code> will assume that the transform needs to be done for all coordinates, and will expect that you have selected corresponding keypoints for the layer all_tiles_coarse.</p> <p>That's it! Now you're ready to go to the next step.</p>"},{"location":"examples/e13_mouse/preprocessing_sequencing/","title":"Preprocessing transcriptomic library","text":"<p>After sequencing, we proceed with the preprocessing of the data, to go from raw reads to transcriptomic information mapped to the mouse genome, in space.</p>"},{"location":"examples/e13_mouse/preprocessing_sequencing/#demultiplexing","title":"Demultiplexing","text":"<p>We got basecall files in <code>bcl</code> format from our sequencing facility.</p> <p>We used <code>bcl2fastq</code> for demultiplexing, using this sample sheet. We used the conda environment where we installed <code>spacemake</code> (see instructions on how to install spacemake), and ran the following commands:</p> <pre><code>(base) user@computer:~$ bcl2fastq \\\n    --no-lane-splitting \\\n    --runfolder-dir /openst/data/0_basecalls/230616_VH01346_22_AAC2LVVHV \\\n    -o /openst/data/1_spacemake_mouse/demultiplexed_data \\\n    --sample-sheet /openst/data/0_sample_sheets/230616_NR_FC_ST_72_76_AT_01.csv\n</code></pre> <p>We obtained <code>fastq</code> files that will be used for the rest of the pipeline, for Read 1 and Read 2. As well, this library was resequenced (add more depth to the data); these resequenced Read 1 and resequenced Read 2 files are available.  Once you download these files, you can move them anywhere in your filesystem. We assume that you have opened a terminal, and you have browsed to your home directory. From there, create a folder <code>openst_e13_mouse_head_demo</code>; browse inside, and create another folder <code>data</code>. Then, copy the folder with the <code>fastq</code> files in here. You should have a structure like:</p> <pre><code>/home/user\n|-- openst_e13_mouse_head_demo\n|   `-- data\n|       `-- fastq\n</code></pre>"},{"location":"examples/e13_mouse/preprocessing_sequencing/#transcriptomic-spatial-mapping-with-spacemake","title":"Transcriptomic &amp; spatial mapping with <code>spacemake</code>","text":"<p>First of all, intialize the conda environment for <code>spacemake</code> <pre><code>(base) user@computer:~$ conda activate spacemake\n(spacemake) user@computer:~$\n</code></pre></p>"},{"location":"examples/e13_mouse/preprocessing_sequencing/#initialize","title":"Initialize","text":"<p>Create two folders inside your <code>openst_e13_mouse_head_demo</code> folder, called <code>spacemake</code> and <code>bins</code>, so you will have:</p> <pre><code>/home/user\n|-- openst_e13_mouse_head_demo\n|   |-- data\n|   |   `-- fastq\n|   |-- spacemake\n|   `-- bins\n</code></pre> <p>Download the DropSeq tools, decompress it, and put it inside the <code>bins</code> subdirectory.</p> <p>Then, following the spacemake Quick start guide, browse to the <code>spacemake</code> directory you just created in the <code>openst_e13_mouse_head_demo</code> folder, and run the initialization:</p> <pre><code>(spacemake) user@computer:~$ cd /home/user/openst_e13_mouse_head_demo/spacemake\n(spacemake) user@computer:/home/user/openst_e13_mouse_head_demo/spacemake$ spacemake init\n    --dropseq_tools /home/user/bins/Drop-seq_tools-2.5.1\n</code></pre>"},{"location":"examples/e13_mouse/preprocessing_sequencing/#configure","title":"Configure","text":"<p>As <code>spacemake</code> comes with no default value for species, before anything can be done, a new species has to be added. In this case, we add mouse; you will need to download the correct <code>fa</code> and <code>gtf</code> files. For instance, you can download the mouse genome from gencode, as well as the annotation.</p> <p>Then, you need to run the following commands (remember, in the same <code>spacemake</code> folder as before, with the <code>spacemake</code> conda environment; we are going to omit <code>(spacemake) user@computer:/home/user/openst_e13_mouse_head_demo/spacemake$</code> for brevity).</p> <pre><code>spacemake config add_species \\\n   --name mouse \\\n   --reference genome \\\n   --sequence GRCm39vM30.genome.fa \\\n   --annotation gencodevM30.annotation.gtf\n\nspacemake config add_species \\\n   --name mouse \\\n   --reference rRNA \\\n   --sequence mouse.rRNA.fa\n\nspacemake config add_species \\\n   --name mouse \\\n   --reference phiX \\\n   --sequence phiX.fa\n</code></pre> <p>Note</p> <p>The <code>.fa</code> and <code>.gtf</code> files for mouse are available for http download under the example datasets page. For instance, you can run:</p> <pre><code># for the mouse genome sequence\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/genomes/GRCm39vM30.genome.fa\"\n# etc...\n</code></pre>"},{"location":"examples/e13_mouse/preprocessing_sequencing/#add-sample","title":"Add sample","text":"<p>Now you need to add the sample data and metadata to <code>spacemake</code>. For this, you will also need the puck (tile) barcode files, which can be generated with the <code>openst</code> package.</p> <p>For simplicity, we provide the tile barcode files that are related to this sample, as well as the coordinate system  for the Illumina flow cell that was used to generate the capture area of this experiment.</p> <p>When downloading the tile barcode files, create a folder under <code>openst_e13_mouse_head_demo/data</code> called <code>tiles</code>. Move the files of the tile barcode files into this folder. Also, move the coordinate file to the <code>puck_data</code> folder in the <code>spacemake</code> directory.</p> <p>Remember! You need to be in the <code>/home/user/openst_e13_mouse_head_demo/spacemake</code> directory (or similar, depending on what you created); then run the following commands:</p> <pre><code># downloading R1 and R2 sequences\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/e13_mouse_head_R1_001.fastq.gz\"\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/e13_mouse_head_R2_001.fastq.gz\"\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/e13_mouse_head_reseq_R1_001.fastq.gz\"\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/e13_mouse_head_reseq_R2_001.fastq.gz\"\n\n# downloading the spatial barcode sequences\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/e13_mouse_head_tiles.tar.xz\"\ntar -xvf e13_mouse_head_tiles.tar.xz\n\nspacemake projects add_sample \\\n    --project_id openst_demo \\\n    --sample_id openst_demo_e13_mouse_head \\\n    --R1 e13_mouse_head_R1_001.fastq.gz e13_mouse_head_reseq_R1_001.fastq.gz \\\n    --R2 e13_mouse_head_R2_001.fastq.gz e13_mouse_head_reseq_R2_001.fastq.gz \\\n    --species mouse \\\n    --puck openst \\\n    --run_mode openst \\\n    --barcode_flavor openst \\\n    --puck_barcode_file e13_mouse_head_tiles/*.txt.gz \\\n    --map_strategy \"bowtie2:phiX-&gt;bowtie2:rRNA-&gt;STAR:genome:final\"\n</code></pre> <p>You can specify the coordinate system by modifying the <code>openst</code> run mode in the <code>config.yaml</code> file that is created after you run the <code>spacemake init</code> command (see above). Modify the following lines from this:</p> <pre><code>openst:\n    coordinate_system: puck_data/openst_coordinates.csv\n    spot_diameter_um: 0.6\n    width_um: 1200\n</code></pre> <p>into this:</p> <pre><code>openst:\n    coordinate_system: puck_data/fc_1_coordinate_system.csv\n    spot_diameter_um: 0.6\n    width_um: 1200\n</code></pre> <p>You can download the coordinate system file from the Open-ST website, for example:</p> <pre><code># download the coordinate system\nwget \"http://bimsbstatic.mdc-berlin.de/rajewsky/openst-public-data/fc_1_coordinate_system.csv\"\ncp fc_1_coordinate_system.csv puck_data/.\n</code></pre>"},{"location":"examples/e13_mouse/preprocessing_sequencing/#run","title":"Run","text":"<p>That's all you need to configure! Now, you can run spacemake with the following:</p> <pre><code>spacemake run --cores 32\n</code></pre> <p>You can modify the number of <code>--cores</code> depending on your local machine; also, you can specify additional arguments to <code>spacemake run</code> - refer to the official documentation.</p>"},{"location":"examples/e13_mouse/preprocessing_sequencing/#expected-output","title":"Expected output","text":"<p>Once <code>spacemake</code> finishes, you will see that several folders and files have been created under <code>projects</code> (inside the <code>spacemake</code> directory). For example, you can check the QC reports in your web browser by opening the file at <code>projects/openst_demo/processed_data/openst_demo_e13_mouse_head/illumina/complete_data/qc_sheets/qc_sheet_openst_demo_e13_mouse_head_fc_1_puck_collection.html</code>, giving you a first impression of what's the quality of spatial mapping, amount of transcripts and genes per barcoded spot, and others.</p> <p>Importantly, you will find files in the directory <code>projects/openst_demo/processed_data/openst_demo_e13_mouse_head/illumina/complete_data/dge</code> with the name <code>dge.all.polyA_adapter_trimmed.mm_included.spatial_beads_*.h5ad</code> (where <code>*</code> is a wildcard). These files, and not the ones containing  the words <code>mesh</code>, <code>hexagon</code> or <code>circle</code> are the ones that will be used later to perform the pairwise alignment with imaging data, and to later reconstruct the cell-by-gene matrix.</p> <p>If you specified options for meshing in the <code>run_mode</code>, there will be a file containing keywords <code>puck_collection</code> and <code>mesh</code>, <code>hexagon</code> or <code>circle</code>. This contains approximate cell-by-gene information, as the transcripts are aggregated by a regular lattice and not by the true spatial arrangement of cells. This might be already enough for some analyses. </p> <p>Anyway... keep going with the tutorial if you want to unleash the full potential of Open-ST.</p>"},{"location":"experimental/capture_area_generation/","title":"Capture area generation","text":"<p>The following section details the generation of capture areas for the Open-ST protocol. </p> <p>By sequencing oligos, which comprise unique 32-nucleotide barcodes, appropriate adapters, and a poly-dT, we register the barcode sequences and their associated coordinates on the flow cell.</p> <p>For instance, you can get ~360 capture areas sized 3x4 mm from a single Illumina\u00ae NovaSeq 6000 S4 flow cell.</p>"},{"location":"experimental/capture_area_generation/#sequencing-of-barcoded-library","title":"Sequencing of barcoded library","text":"<p>When using an Illumina\u00ae NovaSeq 6000 S4 flow cell (35 cycles), sequence the HDMI32-DraI library (see in Oligonucleotides) at a loading concentration of 200 pM.  Using 200 pM library, loaded according to the KAPA qPCR value, we obtained the following quality metrics for the barcoded fc_1 used in our our paper: Q30 &gt;= 86%; PF = 78%; occupied = 97%. Although great results were achieved using this flow cell, 97% occupied is high. Consequently, we suggest to use a titration of library loading concentrations (one concentration per lane) when generating your first barcoded flow cell. </p> <p>Sequence a single-end 37 cycle read, using Read1-DraI oligo as a custom primer. Use a custom sequencing recipe that stops the run immediately after read 1 prior to on-instrument washes. </p> <p>Note</p> <p>The custom recipe published in our bioarchive pre-print and linked above was provided by Illumina Technical Support. It was used in a sequencing run with the following versions: reagent kit v1.5, RTA v3.4.4, Flow Cell Consumable v1, Sbs Consumable v3, NovaSeq control Software v 1.7.5 (in the pre-print) and v 1.8.1 (in an independent flow cell with no published data). Be aware that the custom recipe may change with different versions.  </p>"},{"location":"experimental/capture_area_generation/#expected-data-output","title":"Expected (data) output","text":"<p>Either when using your own sequencing equipment or relying on a sequencing facility, you will get access to (most likely) already demultiplexed <code>fastq</code> files; otherwise, you can get access to raw basecall files in <code>bcl</code> format.</p> <p>Either of these files shall be used as the input for <code>openst</code> later, to create a database of barcode sequences and their spatial locations.</p>"},{"location":"experimental/capture_area_generation/#enzymatic-processing","title":"Enzymatic processing","text":"<p>Tips</p> <ul> <li>Prepare mixes in excess. ~300 \u03bcL per lane is required for the S4 flow cell.</li> <li>If bubbles occur, mark these with pen on the flow cell. Repeat reactions if many bubbles occur and ensure bubbles do not form at the same locations. </li> <li>Use a P1000 pipette and pipette slowly to avoid the formation of bubbles. </li> <li>For removing washes, pipette the liquid out and then blow through air using the P1000 to remove remaining liquid.</li> </ul>"},{"location":"experimental/capture_area_generation/#dra-i-digestion","title":"Dra I digestion","text":"<p>DraI mix</p> Reagent Final concentration Volume (\u03bcL) DraI 2U/\u03bcL 10 10X CutSmart buffer 1x 10 Ultrapure water 80 <ol> <li>Wash flow cell by flowing through 500 \u03bcL ultrapure water using a P1000 pipette.  </li> <li>Add DraI mix and incubate at 37\u00b0C overnight.</li> </ol>"},{"location":"experimental/capture_area_generation/#exonucelase-i-digestion","title":"Exonucelase I digestion","text":"<p>ExoI mix</p> Reagent Final concentration Volume (\u03bcL) ExoI 1 U/\u03bcL 5 10X ExoI buffer 1x 10 Ultrapure water 85 <ol> <li>Wash flow cell by flowing through 500 \u03bcL 80% ethanol, then ultrapure water.</li> <li>Add Exonuclease I mix and incubate for 45 min at 37\u00b0C.</li> <li>Wash flow cell by flowing through 500 \u03bcL ultrapure water three times.</li> </ol>"},{"location":"experimental/capture_area_generation/#opening-denaturation-and-washes","title":"Opening, denaturation and washes","text":"<p>Note</p> <p>The NovaSeq6000 S4 flow cell images the top and bottom glass. Thus, keep both and take care not to break them.  </p> <p>Note</p> <p>Check out our video linked at the end of this page to see a demonstration of the opening of the flow cell. </p> <ol> <li>Remove the flow cell from its plastic encasing. </li> <li>Carefully score along the sides of the flow cell using a scalpell. The blade should be in one plane with the flow cell.</li> <li>Once all sides detach, carefully seperate the two flow cell glasses.</li> <li>Denature the second strand by washing the opened flow cell surfaces in a beaker of 0.1N NaOH, incubating for 5 min.</li> <li>After the denaturation, wash the surfaces 3x with 0.1M Tris-HCl (pH 7.5) and then 3x with Ultrapure water.</li> <li>Let the flow cell surfaces air dry before proceeding with the scoring and breaking of the flow cell surfaces into smaller capture areas. </li> </ol>"},{"location":"experimental/capture_area_generation/#breaking-the-flow-cells-into-capture-areas","title":"Breaking the flow cells into capture areas","text":"<p>Note</p> <p>Capture areas can be stored dry at -20\u00b0C for extended periods of time. We have generated libraries from prepared capture areas stored for 12 months. </p> <p>We have designed a cutting guide that facilitates the breaking of the flow cell into regular capture areas.  We provide the 3D model of the cutting guide as a printable stl file. If you don't have a 3D printer, you can check for 3D printing services near you - they will help you in this endeavor \ud83e\udd17.</p> <p>Once you have the tool, refer to the video where we explain how to use it:</p> <p> Open-ST: breaking the flow cell into capture areas by Marie Schott \u2013  3m \u2013 Learn how to break an Illumina\u00ae NovaSeq 6000 S4 flow cell into capture areas  using our 3D-printable cutting guide.</p>"},{"location":"experimental/getting_started/","title":"Getting started","text":""},{"location":"experimental/getting_started/#materials","title":"Materials","text":"Reagents REAGENT SOURCE IDENTIFIER Dra I enzyme NEB Cat#R0129 Alkaline Phosphatase Calf Intestinal (CIAP) enzyme Promega Cat#M1821 Exonuclease I enzyme NEB Cat#M0293 NaOH solution for molecular biology 10 M in H2O Sigma Cat#72068 UltraPure\u21221M Tris-HCl pH7.5 Invitrogen\u2122 Cat#15567027 Tissue-Tek OCT Sakura Finetek Cat#4583 Methanol (min. 99.8%) Th. Geyer Cat#1437 2-propanol (min 99.9%) Th. Geyer Cat#1197 Mayer\u2019s Haematoxylin Agilent Dako Cat#S3309 Bluing buffer Agilent Dako Cat#CS702 Eosin Y, aqueous Sigma Cat#HT110216 Pepsin from porcine gastric mucosa Sigma Cat#P7000 20x SSC Sigma Cat#S6639-1L Hydrochloric Acid (HCl) 10N AppliChem Cat#187051 BSA Molecular Biology Grade (conc. 20 mg/ml) NEB Cat#B9000S dNTP SET 100mM 4X1mL Life Technologies Cat#R0182 SuperScript IV Reverse Transcriptase Life Technologies Cat#18090010 RiboLock RNase Inhibitor Thermo Scientific Cat#EO0381 Tris-HCl Buffer pH 8.0, 1M Life Technologies Cat#AM9855G Sodium chloride NaCl (5M), RNase-free Invitrogen Cat#AM9760G Roti\u00ae-Stock 20 % SDS ready-to-use, sterile filtered Roth Cat#1057.1 UltraPure 0.5M EDTA, pH 8.0 Life Technologies Cat#15575020 Proteinase K (800 mU/\u03bcL) NEB Cat#P8107S DNA Polymerase Large Fragment exo- Klenow Fragment (3'-5' exo-) NEB Cat#M0212 Ampure XP beads Beckman coulter Cat#A63881 Kapa HiFi Hotstart Readymix KK2612 Roche Cat#7958960001 1.5% Agarose gel, PippinHT (300-1500 bp) Biozym HTC1510 Qubit dsDNA HS Assay Kit Invitrogen Cat#Q32854 High sensitivity DNA kit Agilent Cat#5067-4626 HS RNA tapestation Agilent 5067-5579/5580/5581 Blue S'Green qPCR mix Biozym Cat#331416 KAPA LQ Primer + Mastermix (Illumina/ LC480) Roche Cat#7960573001 KAPA Library Quantification DNA Standards (Illumina) Roche Cat#7960387001 NovaSeq 6000 S4 reagent kit v1.5 (35 cycles) Illumina Cat#20044417 Oligonucleotides OLIGO SEQUENCE COMMENT HDMI32-DraI CAAGCAGAAGACGGCATACGAGATTCTTTCCCTACACGACGCTCTTCCGATCTNNVNBVNNVNNVNNVNNVNNVNNVNNVNNNNNTCTTGTGACTACAGCACCCTCGACTCTCGCTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTAAAGACTTTCACCAGTCCATGATGTGTAGATCTCGGTGGTCGCCGTATCATT Randomer TCAGACGTGTGCTCTTCCGATCTNNNNNNNNN Read1-DraI ATCATGGACTGGTGAAAGTCTTTAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGCGAGAGTCGAGGGTGCTGTAGTCACAAGA p5_fwd AATGATACGGCGACCACCGAGATCTACACTCTTTCCCTACACGACGCTCT\u2217T\u2217C *denotes phosphorothioated DNA bases p7_rev_indexing CAAGCAGAAGACGGCATACGAGAT[8-mer index sequence]GTGACTGGAGTTCAGACGTGTGCTCTTCC\u2217G\u2217A *denotes phosphorothioated DNA bases Equipment <ul> <li>Chemical hood (for work with toxic chemicals, such as Trizol or methanol)  </li> <li>Cryostat </li> <li>Heating block (Can also use hybridisation oven for pre-warming pepsin.)</li> <li>Hybridization oven </li> <li>Brightfield microscope with camera we image using a 20x objective</li> <li>Thermocycler </li> <li>qPCR machine </li> <li>Bluepippin or PippinHT (alternatively, manual run an agarose gel and cut band of desired size range to extract cDNA from)</li> <li>Automated gel electrophoresis machine (eg. Tapestation or BioAnalyzer)</li> <li>Qubit fluorometer (or alternative instrument for measuring DNA concentration)   </li> <li>3D printer (If you don't have a 3D printer, you can check for 3D printing services near you) </li> </ul>"},{"location":"experimental/library_preparation/","title":"Library preparation","text":"<p> Open-ST: capture area handling by Marie Schott &amp; Anastasiya Boltengagen \u2013  1m \u2013 Tips and tricks on handling the capture areas during library preparation.</p>"},{"location":"experimental/library_preparation/#tissue-sectioning","title":"Tissue sectioning","text":"<p>Before starting</p> <p>Before sectioning, place the OCT-mounted fresh frozen tissue in a cryostat for 20 minutes at the selected cutting temperature (adjusted according to tissue). Place the capture areas at room temperature. </p> <p>Before starting</p> <p>Pre-cool 100% methanol at -20\u00b0C for subsequent fixation step. </p> <p>Tip</p> <p>Trim the excess OCT surrounding the tissue to prevent folding of OCT under or over the tissue.  </p> <p>Warning</p> <p>Remove the capture area from the stage, as soon as the transfer occured, to avoid re-freezing of the tissue onto the stage. </p> <ol> <li>Slice the tissue at the selected temperature at 10 \u03bcm thickness.</li> <li>Place the capture area (room temperature) on the tissue section on the cutting stage. The tissue will melt onto the capture area.</li> <li>Store the capture area with tissue-side up in the cryostat until fixation.</li> </ol> <p> Open-ST: sectioning by Marie Schott &amp; Anastasiya Boltengagen \u2013  1m \u2013 Learn how to place cryosections on your Open-ST capture area</p>"},{"location":"experimental/library_preparation/#fixation","title":"Fixation","text":"<p>Note</p> <p>Transport samples on dry ice until placed in -20\u00b0C methanol. </p> <ol> <li>Fix the tissue by placing the capture area with the tissue section in a tube containing 1 mL of 100% Methanol (pre-cooled to -20\u00b0C). </li> <li>Incubate at -20\u00b0C for 30 min.</li> </ol>"},{"location":"experimental/library_preparation/#hematoxilin-and-eosin-he-staining-and-imaging","title":"Hematoxilin and eosin (H&amp;E) staining and imaging","text":"<p> Open-ST: H&amp;E staining by Marie Schott &amp; Anastasiya Boltengagen \u2013  1m \u2013 Capture area handling during staining</p> <p>Buffered Eosin (make fresh)</p> Reagent Volume (\u03bcL) Eosin Y 500 0.45M Tris-Acetate buffer pH 6.0 500 <p>For incubations, add enough volume to cover the capture area completely. For all washes, wash by dipping in a beaker with Ultrapure water (500 mL). </p> <ol> <li>Add isopropanol to the tissues on the capture area and incubate for 1 min, then remove the solution and dry the tissues. </li> <li>Add hematoxylin, and incubate for 5 min.</li> <li>Wash the capture area with Ultrapure water until the hematoxylin dye is completely removed (dipping 10-15x). </li> <li>Add bluing buffer, and incubate for 2 min. </li> <li>Wash the capture area with Ultrapure water, dipping 5 times. </li> <li>Add buffered eosin onto tissue section for 1 min.</li> <li>Wash the capture area with Ultrapure water, dipping 10-15x. </li> <li>Let the capture area air-dry at room temperature for 10 min. Dry the tissues completely with no residual water. </li> <li>Image the tissue on brightfield with the 20x objective. (If using an inverted microscope, put the capture area face-down on a coverslip (#1.5, 24x50mm) for imaging)</li> </ol> <p>After imaging, place the capture areas with the tissue section face up into a multi-well gasket, such as the 16-Well ProChamber Microarray System (Grace Bio-Labs, Cat#645508). We use 100 \u03bcL reaction volume throughout the protocol whilst using the gasket. </p> <p> Open-ST: imaging and incubating by Marie Schott &amp; Anastasiya Boltengagen \u2013  1m \u2013 Imaging and incubating the Open-ST capture areas</p>"},{"location":"experimental/library_preparation/#permeabilization","title":"Permeabilization","text":"<p>We recommend performing a pilot experiment in which you compare different permeabilization conditions using a qPCR assay. We suggest comparing different pepsin incubation times (for example, 0, 15, 30, 45, and 60 min) at 37\u00b0C.   Follow the library preparation steps until qPCR for cycle number assessment. Earlier amplification corresponds to a higher concentration of starting material, ie. more efficient mRNA capture. If conditions amplify together, chose the shorter time or lower pepsin concentration for permeabilization of your sample.  </p> <p>Note</p> <p>To prevent evaporation use plate sealing tape to seal your multiwell chamber during all following incubations in the chamber. </p> <ol> <li>Weigh and dissolve the pepsin to have a solution with 7 U/ul pepsin in 2xSSC pH 2.5. </li> <li>Dilute 1:10 with 2xSSC pH 2.5 to get the final concentration of 0.7 U/\u03bcl.</li> <li>Prewarm permeabilization mix (0.7 U/uL) at 37\u2103 several minutes before use. </li> <li>Incubate at 37\u00b0C for X min (ex. 15 min - 30 min - 60 min) according to the tissue used.  </li> </ol>"},{"location":"experimental/library_preparation/#reverse-transcription","title":"Reverse transcription","text":"<p>Reverse transcription (RT) buffer </p> Reagent Final concentration Volume (\u03bcl) SSIV 5X rt BUFFER 1x 20 RNase inhibitor (40U/ul) 1U/ul 2.5 Ultrapure water 77.5 Total 100 <p>Reverse transcription mix </p> Reagent Final concentration Volume (\u03bcl) SSIV 5X rt BUFFER 1x 20 0.1M DTT 5mM 5 BSA (20mg/ml) 0.187mg/ml 0.93 10mM dNTP mix 1mM 10 Superscript IV (200U/ul) 6.67 U/\u03bcL 3.33 Ribolock(40U/\u03bcL) 1U 2.5 Ultrapure water 58.24 Total 100 <ol> <li>Remove the pepsin solution. </li> <li>Wash the capture area carefully with 100 \u03bcl RT Buffer once.</li> <li>Add 100 \u03bcL RT mix per capture area. Seal the multiwell chamber with a piece of plate-sealing tape to prevent evaporation. Incubate overnight at 42\u00b0C. </li> </ol>"},{"location":"experimental/library_preparation/#exo-i-digestion","title":"Exo I digestion","text":"<p>Exonuclease I mix </p> Reagent Final concentration Volume (\u03bcl) 10 x Exo I buffer 1x 10 Exo I 1U/ul 5 Ultrapure water 85 Total 100 <ol> <li>Remove the RT solution. </li> <li>Add 100 \u03bcL Exonuclease I mix per capture area to eliminate DNA that did not hybridize with mRNA.  </li> <li>Seal chamber and incubate 45 min at 37\u2103. </li> </ol>"},{"location":"experimental/library_preparation/#tissue-removal","title":"Tissue removal","text":"<p>Tissue removal mix </p> Reagent Final concentration Volume (\u03bcL) 1M Tris-Cl pH 8.0 100 mM 10 2M NaCl 200 mM 10 20% SDS 2% 10 0.1M EDTA 5 mM 5 Proteinase K ( 800 mU/\u03bcL) 16 mU/\u03bcL 2 Nuclease -free water 63 Total 100 <ol> <li>Remove the Exonuclease I mix. </li> <li>Add 100 \u03bcl of 1x tissue removal mix per capture area, seal chamber, and incubate for 40 minutes at 37\u2103.</li> <li>Wash as follows: <ol> <li>Wash the capture area with ultrapure water three times. </li> <li>Wash the capture area  with 100 \u03bcl of freshly prepared 0.1N NaOH three times* (*each with 5 min incubation at room temperature). </li> <li>Wash the capture area  with 100 \u03bcl of 0.1M Tris (pH7.5) three times. </li> <li>Wash the capture area with 100 \u03bcl of Ultrapure water three times. </li> </ol> </li> </ol> <p>Note</p> <p>Visually confirm that tissue removal is complete after washes have been completed. </p>"},{"location":"experimental/library_preparation/#second-strand-synthesis","title":"Second strand synthesis","text":"<p>Second strand synthesis mix</p> Reagent Final concentration Volume (\u03bcL) NEBuffer-2 1x 10 100 uM randomer 10 uM 10 10 mM dNTPs 1 mM 10 Klenow exo (-) Fragment (5 U/\u03bcL) 0.5 U/\u03bcL 10 Ultrapure water 60 Total 100 <ol> <li>Add 100 \u03bcL second strand synthesis mix per capture area. Seal chamber and incubate at 37\u00b0C for 2 h. </li> <li>Wash with 100 \u03bcL ultrapure water 3 times. </li> <li>Elute the second strand product by incubating the capture areas in 100 \u03bcl of freshly prepared 0.1 N NaOH twice for 5 min each. Recover the elutions (=2<sup>nd</sup> strand product), pooling the two elutions per sample.</li> <li>Mix the 200 \u03bcl of second strand product per sample with 28.6 \u03bcl of 1M Tris-HCl pH 7.5. Proceed directly to next step.</li> </ol> <p>Purify the 228.6 \u03bcL elution using AmpureXP beads at a ratio of 1.8 beads to 1x second strand product (=411 \u03bcL beads/sample) , following the manufacturer's instructions. Elute the product in 82.5 \u03bcL ultrapure water.  </p>"},{"location":"experimental/library_preparation/#qpcr-for-cycle-number-assessment","title":"qPCR for cycle number assessment","text":"<p>Note</p> <p>Use of a passive reference dye depends on the qPCR cycler used. We usually use the StepOne\u2122 Real-Time PCR System (Applied Biosystems).  </p> <p>Pipette and run a qPCR to determine the appropriate cycle number to amplify your eluted second strands. </p> <p>qPCR mix</p> Reagent Final concentration Volume (\u03bcl) 2x Blue S'Green qPCR mix + ROX 1x 10 10 uM p5_fwd primer 1 uM 2 10 uM p7_rev_indexing primer 1 uM 2 Second strand product 2.5 Ultrapure water 3.5 Total 20 Temperature Time Cycles 95\u00b0C 3 min 1 95\u00b0C 30 sec (40) 60\u00b0C 1 min (40) 72\u00b0C 1 min (40) <p>Derive the PCR cycle number required for the amplification of your sample as follows: </p> <p>Set a threshold at 50% of the peak \u0394Rn. For each sample determine the cycle number at the intersection of the threshold and amplification curve.  Subtract 5 cycles to account fo the qPCR input (3%). This number is your recommended PCR cycle number. We expect a cycling number between 11 and 14. </p>"},{"location":"experimental/library_preparation/#library-construction","title":"Library construction","text":""},{"location":"experimental/library_preparation/#library-amplification-and-purification","title":"Library amplification and purification","text":"<p>Library amplification mix</p> Reagent Final concentration Volume (\u03bcL) 2x KAPA HiFi Hotstart Readymix 1x 100 100 uM p5_fwd primer 1 uM 2 100 uM p7_rev_indexing primer 1 uM 2 Purified 2<sup>nd</sup> strand 80 Ultrapure water 16 Total 200 Temperature Time Cycles 95\u00b0C 3 min 1 95\u00b0C 30 sec (To be determined) 60\u00b0C 1 min (To be determined) 72\u00b0C 1 min (To be determined) 72\u00b0C 2 min 1 4\u00b0C hold <ol> <li>Prepare the library amplification mix per sample. </li> <li>Split each sample mix into four PCR tubes, each with 50 \u03bcL volume. </li> <li>Run the PCR with the cycle number determined previously (3.9). </li> <li>Pool the 200 \u03bcL PCR product per sample and purify using AmpureXP beads at a 1:1 ratio of beads PCR product, following the manufacturer's instructions.</li> <li>Elute the PCR product in 20 \u03bcL ultrapure water.</li> <li>Optionally measure the library concentration (e.g using the Qubit) and check the library profile using automated gel electrophoresis before proceeding to gel-based size selection. </li> </ol> <p></p> Example BioAnalyzer profile before size selection"},{"location":"experimental/library_preparation/#size-selection","title":"Size selection","text":"<p>Perform size selection of your sample to obtain fragments 350 - 1100 bp. Use the Bluepippin or PippinHT 1.5% agarose gel and follow the manufacturer's instructions.  Measure the concentration of your size-selected product using the Qubit dsDNA quanitification kit and analyze the library profile using automated gel electrophoresis (e.g. BioAnalyzer or Tapestation) </p> <p></p> Example BioAnalyzer profile after size selection"},{"location":"experimental/sequencing_of_openst_library/","title":"Sequencing of Open-ST library","text":""},{"location":"experimental/sequencing_of_openst_library/#quantification","title":"Quantification","text":"<p>We recommend quantifying your libraries for sequencing using the KAPA Library Quantification Kit.</p>"},{"location":"experimental/sequencing_of_openst_library/#loading-and-sequencing","title":"Loading and sequencing","text":"<p>The optimal loading concentration depends on the sequencer used. For the Illumina\u00ae NovaSeq 6000 we obtained optimal clustering at a loading concentration of 130 pM. For the Illumina\u00ae NextSeq 2000 sequencing system we recommend a loading concentration of 650 pM.   </p> <p>Moreover, Illumina suggests a minimum spike-in of 1% PhiX into the pool as a quality control for cluster generation, sequencing, and alignment. </p> <p>In our setup, the following read lengths were used:</p> Read Cycles Read 1 28-32 Index 1 8 Index 2 NA Read2 90+"},{"location":"experimental/sequencing_of_openst_library/#expected-data-output","title":"Expected (data) output","text":"<p>Either when using your own sequencing equipment or relying on a sequencing facility, you will get access to (most likely) already demultiplexed <code>fastq</code> files; otherwise, you can get access to the raw basecall files in <code>bcl</code> format.</p> <p>Either of these files shall be used as the input for spacemake later.</p>"},{"location":"experimental/tissue_processing_and_RNA_qc/","title":"Tissue processing and RNA quality control","text":"<p>Open-ST requires the use of unfixed fresh-frozen tissue. We recommend following 10X Visium's protocol for simultaneous freezing and embedding in their Tissue Preparation guide.</p> <p>Test for RNA quality of the OCT-embedded tissue before working with a tissue.  For this we recommend cutting 5-10 sections of tissue at 10 um thickness. Remove excess OCT as possible and collect the tissue sections in a pre-cooled 1.5 mL tube. Extract total RNA and assess the RNA quality on an automated gel electrophoresis machine, such as the BioAnalyzer or TapeStation. </p> <p>Aim for an RNA integrity number (RIN) over 7. Samples with lower RIN values can be used for Open-ST; however, low RNA integrity negatively impacts library quality.</p>"},{"location":"static/examples/notebooks/e13_head_eda/","title":"Exploratory analysis (Jupyter)","text":"<p>We will do some exploratory data analysis on the adult mouse hippocampus dataset that you just preprocessed.</p> <p>Here, we show our code and results as a jupyter notebook, but you can copy and paste the code into a standalone script, and it will still work.</p> <pre><code>import scanpy as sc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n</code></pre> <pre><code>adata = sc.read_h5ad(\"alignment/openst_demo_e13_mouse_head_by_cell.h5ad\")\n</code></pre> <p>After transfering the segmentation information, the cell with the identifier 0 will have all the transcripts belonging to the background.  Therefore, make sure to omit it from the dataset.</p> <p>Tip</p> <p>We all know that views in <code>anndata</code> can be a bit problematic sometimes... You might want to append <code>.copy()</code> at the end of the following line of code if you encounter issues.</p> <pre><code>adata = adata[adata.obs.cell_ID_mask != 0].copy()\n</code></pre> <pre><code>sc.pp.calculate_qc_metrics(adata, inplace=True)\nadata.var[\"mt\"] = adata.var_names.str.startswith(\"mt-\")\nsc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n</code></pre> <pre><code>fig, axs = plt.subplots(1, 3, figsize=(12, 4))\nsns.histplot(adata.obs[\"total_counts\"], kde=False, bins=60, ax=axs[0])\naxs[0].axvline(250, 0,19000)\nsns.histplot(adata.obs[\"pct_counts_mt\"], kde=False, bins=60, ax=axs[1])\nsns.histplot(adata.obs[\"n_genes_by_counts\"], kde=False, bins=60, ax=axs[2])\n</code></pre> <pre>\n<code>&lt;AxesSubplot: xlabel='n_genes_by_counts', ylabel='Count'&gt;</code>\n</pre> <p>Here we apply the following filters, decided by looking at the histogram. You can be more conservative, we chose these in order to keep most of the cells while removing very obvious bad quality data points.</p> <pre><code># Filter data\nsc.pp.filter_cells(adata, min_counts=250)\nsc.pp.filter_cells(adata, max_counts=10000)\n# sc.pp.filter_cells(adata, max_counts=35000)\nadata = adata[adata.obs[\"pct_counts_mt\"] &amp;lt; 20]\nprint(f\"#cells after MT filter: {adata.n_obs}\")\nsc.pp.filter_genes(adata, min_cells=10) \n</code></pre> <pre>\n<code>#cells after MT filter: 49687\n</code>\n</pre> <pre>\n<code>/home/dleonpe/miniconda3/envs/napari-env/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n  adata.var['n_cells'] = number\n</code>\n</pre> <p>From this point, some of the analysis decisions are just heuristics taken from single cell analysis. We would not say these are the best possible practices for analyzing this data, but the most common ones. Especially, regarding normalization (see Warning below).</p> <p>Let's apply the common normalization to \\(10^4\\) counts per cell, and the log-normalization with pseudocount. This is supposed to stabilize the variance of genes and remove potential biases from sequencing depth per cell.</p> <pre><code>sc.pp.normalize_total(adata, inplace=True)\nsc.pp.log1p(adata)\n</code></pre> <p>Warning</p> <p>Normalization is necessary, i.e., to account for the differences in depth per cell and remove potential biases, or to estabilize the variance of genes and remove their dependency on the counts. </p> <p>It is still under study, but normalization strategies for single-cell are most likely not well suited for this kind of high-resolution, single-cell spatial data. Especially, since counts have an additional source of (spatial) coviariance that does not exist in single-cell datasets. Therefore, it is possible that the covariance and errors from spatial components are propagated throughout the analysis pipeline, and some signal or significant results are just noise from the spatial autocorrelations. Anyway, we are using these common practices just as a way of getting a feeling about the data, and what could be genes playing a role at specific regions in space.</p> <p>Now, we detect highly variable genes. Any of the <code>flavor</code>(s) are designed with single-cell data in mind, so the list of highly variable genes that they select will be likely affected by the spatial autocorrelation structure. Alternative strategies could be selecting these genes based on the spatial variable genes (e.g., by Moran's I value).</p> <pre><code>sc.pp.highly_variable_genes(adata, flavor=\"seurat\", n_top_genes=2000)\n</code></pre> <p>We perform the dimensionality reduction with PCA, and community clustering of the nearest neighbors graph using the leiden algorithm. For this exploratory analysis, we keep the default parameters.</p> <p>TODO: put the PCA loadings and select from this.</p> <pre><code># Clustering &amp;amp; embedding\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata, resolution = 0.9, key_added=\"leiden\")\n</code></pre> <p>Now we can take a look at the clusters in space. It seems like we recapitulate the major morphological structures from this tissue. We also show Ttr, a marker of the choroid plexus, which seems to be restricted to a specific location in space, that also clusters separately.</p> <pre><code>plt.rcParams[\"figure.figsize\"] = (8, 8)\nsc.pl.spatial(adata, img_key=None, color=[\"total_counts\", \"n_genes_by_counts\", \"leiden\", \"Ttr\"], spot_size=40)\n</code></pre> <p>Notice how we didn't compute the typical UMAP. It might be useful in single cell data, but it does not mean much in this kind of spatial data. Basically, since the data per cell is not normalized using an appropriate method taking into account the spatial autocorrelation, the neighborhood graph might have bias depending on the local environment. Thus, UMAP amplifies this fact and leaves a visualization that is a mere picture of the physical 2d 'neighborhood' topology of the cells, rather than representing the local/global distances in transcriptomic space.</p> <pre><code>sc.tl.umap(adata)\n</code></pre> <pre><code>plt.rcParams[\"figure.figsize\"] = (4, 4)\nsc.pl.umap(adata, color=[\"total_counts\", \"n_genes_by_counts\", \"leiden\", \"Ttr\"], wspace=0.4, legend_loc = \"on data\")\n</code></pre> <pre>\n<code>/home/dleonpe/miniconda3/envs/napari-env/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n</code>\n</pre> <p>A better way (compared to UMAP) of showing the pairwise relations of clusters and their transcriptomic identities is to use feature plots like dotplots or matrixplots showing the expression of significant markers of the inferred clusters, sorted following their dendrogram.</p> <pre><code>sc.tl.rank_genes_groups(adata, 'leiden')\nsc.tl.dendrogram(adata, 'leiden')\n</code></pre> <pre>\n<code>WARNING: Default of the method has been changed to 't-test' from 't-test_overestim_var'\n</code>\n</pre> <pre><code>sc.pl.rank_genes_groups_dotplot(adata, n_genes=3, standard_scale='var', min_logfoldchange=1)\n</code></pre> <pre>\n<code>/home/dleonpe/miniconda3/envs/napari-env/lib/python3.9/site-packages/scanpy/plotting/_dotplot.py:749: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap', 'norm' will be ignored\n  dot_ax.scatter(x, y, **kwds)\n</code>\n</pre> <p>For instance, this confirms how Ttr is indeed a significant marker of cluster 11, which we could indeed annotate as choroid plexus.</p>"},{"location":"static/examples/notebooks/e13_head_eda/#loading-the-modules","title":"Loading the modules","text":""},{"location":"static/examples/notebooks/e13_head_eda/#loading-the-data","title":"Loading the data","text":""},{"location":"static/examples/notebooks/e13_head_eda/#calculating-qc-metrics-of-the-sample","title":"Calculating QC metrics of the sample","text":"<p>Now, we can show different plots (histograms) to assess the number of unique transcripts (UMIs), genes, percentage of mitochondrial transcripts per segmented cell, as a quick way of assessing the quality of the dataset. This will help to decide on filtering thresholds, to remove potential low quality cells (i.e., due to poor sequencing coverage, or wrong segmentation of background as cells).</p>"},{"location":"static/examples/notebooks/e13_head_eda/#normalization","title":"Normalization","text":""},{"location":"static/examples/notebooks/e13_head_eda/#dimensionality-reduction-and-clustering","title":"Dimensionality reduction and clustering","text":""},{"location":"static/examples/notebooks/e13_head_eda/#marker-genes","title":"Marker genes","text":""},{"location":"static/examples/notebooks/hypo_adult_eda/","title":"Exploratory analysis (Jupyter)","text":"<p>We will do some exploratory data analysis on the adult mouse hippocampus dataset that you just preprocessed.</p> <p>Here, we show our code and results as a jupyter notebook, but you can copy and paste the code into a standalone script, and it will still work.</p> <pre><code>import scanpy as sc\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n</code></pre> <pre><code>adata = sc.read_h5ad(\"alignment/openst_demo_adult_mouse_by_cell.h5ad\")\n</code></pre> <p>After transfering the segmentation information, the cell with the identifier 0 will have all the transcripts belonging to the background.  Therefore, make sure to omit it from the dataset.</p> <p>Tip</p> <p>We all know that views in <code>anndata</code> can be a bit problematic sometimes... You might want to append <code>.copy()</code> at the end of the following line of code if you encounter issues.</p> <pre><code>adata = adata[adata.obs.cell_ID_mask != 0].copy()\n</code></pre> <pre><code>sc.pp.calculate_qc_metrics(adata, inplace=True)\nadata.var[\"mt\"] = adata.var_names.str.startswith(\"mt-\")\nsc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n</code></pre> <pre><code>fig, axs = plt.subplots(1, 3, figsize=(12, 4))\nsns.histplot(adata.obs[\"total_counts\"], kde=False, bins=60, ax=axs[0])\naxs[0].axvline(75, 0,19000)\nsns.histplot(adata.obs[\"pct_counts_mt\"], kde=False, bins=60, ax=axs[1])\nsns.histplot(adata.obs[\"n_genes_by_counts\"], kde=False, bins=60, ax=axs[2])\n</code></pre> <pre>\n<code>&lt;AxesSubplot: xlabel='n_genes_by_counts', ylabel='Count'&gt;</code>\n</pre> <p>Here we apply the following filters, decided by looking at the histogram. You can be more conservative, we chose these in order to keep most of the cells while removing very obvious bad quality data points.</p> <pre><code># Filter data\nsc.pp.filter_cells(adata, min_counts=75)\nsc.pp.filter_cells(adata, max_counts=10000)\n# sc.pp.filter_cells(adata, max_counts=35000)\nadata = adata[adata.obs[\"pct_counts_mt\"] &amp;lt; 30]\nprint(f\"#cells after MT filter: {adata.n_obs}\")\nsc.pp.filter_genes(adata, min_cells=10) \n</code></pre> <pre>\n<code>#cells after MT filter: 39087\n</code>\n</pre> <pre>\n<code>/home/dleonpe/miniconda3/envs/napari-env/lib/python3.9/site-packages/scanpy/preprocessing/_simple.py:251: ImplicitModificationWarning: Trying to modify attribute `.var` of view, initializing view as actual.\n  adata.var['n_cells'] = number\n</code>\n</pre> <p>From this point, some of the analysis decisions are just heuristics taken from single cell analysis. We would not say these are the best possible practices for analyzing this data, but the most common ones. Especially, regarding normalization (see Warning below).</p> <p>Let's apply the common normalization to \\(10^4\\) counts per cell, and the log-normalization with pseudocount. This is supposed to stabilize the variance of genes and remove potential biases from sequencing depth per cell.</p> <pre><code>sc.pp.normalize_total(adata, inplace=True)\nsc.pp.log1p(adata)\n</code></pre> <p>Warning</p> <p>Normalization is necessary, i.e., to account for the differences in depth per cell and remove potential biases, or to estabilize the variance of genes and remove their dependency on the counts. </p> <p>It is still under study, but normalization strategies for single-cell are most likely not well suited for this kind of high-resolution, single-cell spatial data. Especially, since counts have an additional source of (spatial) coviariance that does not exist in single-cell datasets. Therefore, it is possible that the covariance and errors from spatial components are propagated throughout the analysis pipeline, and some signal or significant results are just noise from the spatial autocorrelations. Anyway, we are using these common practices just as a way of getting a feeling about the data, and what could be genes playing a role at specific regions in space.</p> <p>Now, we detect highly variable genes. Any of the <code>flavor</code>(s) are designed with single-cell data in mind, so the list of highly variable genes that they select will be likely affected by the spatial autocorrelation structure. Alternative strategies could be selecting these genes based on the spatial variable genes (e.g., by Moran's I value).</p> <pre><code>sc.pp.highly_variable_genes(adata, flavor=\"seurat\", n_top_genes=2000)\n</code></pre> <p>We perform the dimensionality reduction with PCA, and community clustering of the nearest neighbors graph using the leiden algorithm. For this exploratory analysis, we keep the default parameters.</p> <p>TODO: put the PCA loadings and select from this.</p> <pre><code># Clustering &amp;amp; embedding\nsc.pp.pca(adata)\nsc.pp.neighbors(adata)\nsc.tl.leiden(adata, resolution = 0.9, key_added=\"leiden\")\n</code></pre> <p>Now we can take a look at the clusters in space. It seems like we recapitulate the major morphological structures from this tissue. We also show Ttr, a marker of the choroid plexus, which seems to be restricted to a specific location in space, that also clusters separately.</p> <pre><code>plt.rcParams[\"figure.figsize\"] = (8, 8)\nsc.pl.spatial(adata, img_key=None, color=[\"total_counts\", \"n_genes_by_counts\", \"leiden\", \"Ttr\"], spot_size=40)\n</code></pre> <p>Notice how we didn't compute the typical UMAP. It might be useful in single cell data, but it does not mean much in this kind of spatial data. Basically, since the data per cell is not normalized using an appropriate method taking into account the spatial autocorrelation, the neighborhood graph might have bias depending on the local environment. Thus, UMAP amplifies this fact and leaves a visualization that is a mere picture of the physical 2d 'neighborhood' topology of the cells, rather than representing the local/global distances in transcriptomic space.</p> <pre><code>sc.tl.umap(adata)\n</code></pre> <pre><code>plt.rcParams[\"figure.figsize\"] = (4, 4)\nsc.pl.umap(adata, color=[\"total_counts\", \"n_genes_by_counts\", \"leiden\", \"Ttr\"], wspace=0.4, legend_loc = \"on data\")\n</code></pre> <pre>\n<code>/home/dleonpe/miniconda3/envs/napari-env/lib/python3.9/site-packages/scanpy/plotting/_tools/scatterplots.py:392: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored\n  cax = scatter(\n</code>\n</pre> <p>A better way (compared to UMAP) of showing the pairwise relations of clusters and their transcriptomic identities is to use feature plots like dotplots or matrixplots showing the expression of significant markers of the inferred clusters, sorted following their dendrogram.</p> <pre><code>sc.tl.rank_genes_groups(adata, 'leiden')\nsc.tl.dendrogram(adata, 'leiden')\n</code></pre> <pre><code>sc.pl.rank_genes_groups_dotplot(adata, n_genes=3, standard_scale='var', min_logfoldchange=1)\n</code></pre> <pre>\n<code>/home/dleonpe/miniconda3/envs/napari-env/lib/python3.9/site-packages/scanpy/plotting/_dotplot.py:749: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap', 'norm' will be ignored\n  dot_ax.scatter(x, y, **kwds)\n</code>\n</pre> <p>For instance, this confirms how Ttr is indeed a significant marker of cluster 12, which we could indeed annotate as choroid plexus.</p>"},{"location":"static/examples/notebooks/hypo_adult_eda/#loading-the-modules","title":"Loading the modules","text":""},{"location":"static/examples/notebooks/hypo_adult_eda/#loading-the-data","title":"Loading the data","text":""},{"location":"static/examples/notebooks/hypo_adult_eda/#calculating-qc-metrics-of-the-sample","title":"Calculating QC metrics of the sample","text":"<p>Now, we can show different plots (histograms) to assess the number of unique transcripts (UMIs), genes, percentage of mitochondrial transcripts per segmented cell, as a quick way of assessing the quality of the dataset. This will help to decide on filtering thresholds, to remove potential low quality cells (i.e., due to poor sequencing coverage, or wrong segmentation of background as cells).</p>"},{"location":"static/examples/notebooks/hypo_adult_eda/#normalization","title":"Normalization","text":""},{"location":"static/examples/notebooks/hypo_adult_eda/#dimensionality-reduction-and-clustering","title":"Dimensionality reduction and clustering","text":""},{"location":"static/examples/notebooks/hypo_adult_eda/#marker-genes","title":"Marker genes","text":""}]}